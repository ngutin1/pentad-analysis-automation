{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transcribing and processing Harris 2024 event speeches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## dependencies \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWCK4b5DE1UJ",
        "outputId": "8f6e3815-f9cf-4977-8756-2fb1806ee3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yt-dlp in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (2025.3.31)\n",
            "Requirement already satisfied: whisper-timestamped in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (1.15.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: Cython in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from whisper-timestamped) (3.0.12)\n",
            "Requirement already satisfied: dtw-python in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from whisper-timestamped) (1.5.3)\n",
            "Requirement already satisfied: openai-whisper in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from whisper-timestamped) (20240930)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from dtw-python->whisper-timestamped) (1.13.1)\n",
            "Requirement already satisfied: numba in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from openai-whisper->whisper-timestamped) (0.60.0)\n",
            "Requirement already satisfied: torch in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from openai-whisper->whisper-timestamped) (2.0.1)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from openai-whisper->whisper-timestamped) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from openai-whisper->whisper-timestamped) (0.9.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from numba->openai-whisper->whisper-timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from tiktoken->openai-whisper->whisper-timestamped) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from tiktoken->openai-whisper->whisper-timestamped) (2.32.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from torch->openai-whisper->whisper-timestamped) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from torch->openai-whisper->whisper-timestamped) (4.13.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from torch->openai-whisper->whisper-timestamped) (1.13.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from torch->openai-whisper->whisper-timestamped) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from torch->openai-whisper->whisper-timestamped) (3.1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from jinja2->torch->openai-whisper->whisper-timestamped) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages (from sympy->torch->openai-whisper->whisper-timestamped) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp whisper-timestamped pandas tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ffmpeg installation on machine is required for yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.13.0 tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnIy6u6hh23i",
        "outputId": "8a1e3fd6-4c07-49c8-de05-94167e722d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\nicho\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0\n",
            "  Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.0)\n",
            "Collecting huggingface-hub>=0.20.0\n",
            "  Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
            "Requirement already satisfied: Pillow in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\nicho\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\nicho\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
            "Installing collected packages: huggingface-hub, transformers, sentence-transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.16.4\n",
            "    Uninstalling huggingface-hub-0.16.4:\n",
            "      Successfully uninstalled huggingface-hub-0.16.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.30.0\n",
            "    Uninstalling transformers-4.30.0:\n",
            "      Successfully uninstalled transformers-4.30.0\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 2.2.2\n",
            "    Uninstalling sentence-transformers-2.2.2:\n",
            "      Successfully uninstalled sentence-transformers-2.2.2\n",
            "Successfully installed huggingface-hub-0.30.2 sentence-transformers-4.1.0 transformers-4.51.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\nicho\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Script to transcribe and Chunk "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ov6baN0LJMc",
        "outputId": "f00b045c-7a3c-4049-8ded-52b6d4a77e90"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import whisper_timestamped\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "def download_audio(youtube_url, start_time, duration=None):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }],\n",
        "        'outtmpl': 'audio',\n",
        "        'ffmpeg_location': r\"C:\\Users\\nicho\\Documents\\ffmpeg-master-latest-win64-gpl-shared\\bin\"  \n",
        "    }\n",
        "\n",
        "    if duration:\n",
        "        ydl_opts['download_ranges'] = lambda info: [[start_time, start_time + duration]]\n",
        "        ydl_opts['force_keyframes_at_cuts'] = True\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "\n",
        "def transcribe_audio(start_time_seconds):\n",
        "    model = whisper_timestamped.load_model(\"medium\")\n",
        "    audio_path = \"audio.wav\"\n",
        "\n",
        "    result = whisper_timestamped.transcribe(model, audio_path)\n",
        "\n",
        "    for segment in result['segments']:\n",
        "        # Adjust timestamps relative to the start time\n",
        "        segment['start'] += start_time_seconds\n",
        "        segment['end'] += start_time_seconds\n",
        "        print(f\"[{segment['start']:.2f}s -> {segment['end']:.2f}s] {segment['text']}\")\n",
        "\n",
        "\n",
        "def new_transcribe_audio(start_time_seconds, video_id=None, event_date=None, location=None):\n",
        "    \"\"\"\n",
        "    Transcribe audio and return formatted data ready for DataFrame insertion\n",
        "\n",
        "    Parameters:\n",
        "    - start_time_seconds: Offset to add to all timestamps\n",
        "    - video_id: Optional YouTube video ID for reference\n",
        "    - event_date: Optional date of the rally\n",
        "    - location: Optional location of the rally\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with transcription data and metadata\n",
        "    - List of segment dictionaries for adding to DataFrame rows\n",
        "    \"\"\"\n",
        "    model = whisper_timestamped.load_model(\"small\")\n",
        "    audio_path = \"audio.wav\"\n",
        "\n",
        "    result = whisper_timestamped.transcribe(model, audio_path)\n",
        "\n",
        "    # Adjust timestamps relative to the start time\n",
        "    for segment in result['segments']:\n",
        "        segment['start'] += start_time_seconds\n",
        "        segment['end'] += start_time_seconds\n",
        "\n",
        "    # Create a clean formatted transcript with timestamps\n",
        "    formatted_transcript = \"\\n\".join([\n",
        "        f\"[{segment['start']:.2f}s -> {segment['end']:.2f}s] {segment['text']}\"\n",
        "        for segment in result['segments']\n",
        "    ])\n",
        "\n",
        "    # Create a clean text-only transcript\n",
        "    full_text = \" \".join([segment['text'] for segment in result['segments']])\n",
        "\n",
        "    # Create metadata dictionary\n",
        "    transcript_data = {\n",
        "        \"video_id\": video_id,\n",
        "        \"event_date\": event_date,\n",
        "        \"location\": location,\n",
        "        \"start_time\": start_time_seconds,\n",
        "        \"segments\": result['segments'],\n",
        "        \"formatted_transcript\": formatted_transcript,\n",
        "        \"full_text\": full_text\n",
        "    }\n",
        "\n",
        "    # Create a list of segments for row-by-row DataFrame insertion\n",
        "    segment_rows = []\n",
        "    for segment in result['segments']:\n",
        "        segment_rows.append({\n",
        "            \"video_id\": video_id,\n",
        "            \"event_date\": event_date,\n",
        "            \"location\": location,\n",
        "            \"start_time\": segment['start'],\n",
        "            \"end_time\": segment['end'],\n",
        "            \"duration\": segment['end'] - segment['start'],\n",
        "            \"text\": segment['text']\n",
        "        })\n",
        "\n",
        "    return transcript_data, segment_rows\n",
        "\n",
        "\n",
        "def clean_transcript(text, min_repeat_threshold=3, min_word_length=2):\n",
        "\n",
        "    \"\"\"\n",
        "    Clean transcript text by removing repetitive chants, audience responses, and noise.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The transcript text to clean\n",
        "    - min_repeat_threshold (int): Minimum repeats to consider as a chant\n",
        "    - min_word_length (int): Minimum word length to consider for repetition analysis\n",
        "\n",
        "    Returns:\n",
        "    - str: Cleaned transcript text\n",
        "    \"\"\"\n",
        "\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Split into lines for processing\n",
        "    lines = text.split('\\n')\n",
        "    cleaned_lines = []\n",
        "\n",
        "    # Process each line\n",
        "    for line in lines:\n",
        "        # Skip lines that are entirely timestamps\n",
        "        if re.match(r'^\\[\\d+\\.\\d+s -> \\d+\\.\\d+s\\]\\s*$', line):\n",
        "            continue\n",
        "\n",
        "        # Extract text from timestamped lines\n",
        "        timestamp_match = re.match(r'^\\[\\d+\\.\\d+s -> \\d+\\.\\d+s\\]\\s*(.*)', line)\n",
        "        if timestamp_match:\n",
        "            line = timestamp_match.group(1)\n",
        "\n",
        "        # Skip empty lines\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        # Check for repetitive words in the line (chants)\n",
        "        words = re.findall(r'\\b\\w+\\b', line.lower())\n",
        "        word_counts = Counter([w for w in words if len(w) >= min_word_length])\n",
        "\n",
        "        # Skip lines that are repetitive chants\n",
        "        if any(count >= min_repeat_threshold for word, count in word_counts.items()):\n",
        "            most_common = word_counts.most_common(1)\n",
        "            if most_common and most_common[0][1] / len(words) > 0.4:  # If >40% is the same word\n",
        "                # It's likely a chant - check if it's audience response\n",
        "                chant_word = most_common[0][0]\n",
        "                audience_responses = ['thank', 'trump', 'yes', 'applause', 'clap', 'cheer']\n",
        "                if chant_word in audience_responses:\n",
        "                    continue\n",
        "\n",
        "        # Remove sections of thank you repeats\n",
        "        line = re.sub(r'(thank you,?\\s*){3,}', 'thank you ', line, flags=re.IGNORECASE)\n",
        "\n",
        "        # Add to cleaned lines if it has meaningful content\n",
        "        if len(line.strip()) > 0:\n",
        "            cleaned_lines.append(line.strip())\n",
        "\n",
        "    # Final cleaning - consolidate sequential short audience responses\n",
        "    final_lines = []\n",
        "    skip_next = False\n",
        "\n",
        "    for i in range(len(cleaned_lines)):\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue\n",
        "\n",
        "        # Check if this is a very short line followed by another short line (likely audience response)\n",
        "        if i < len(cleaned_lines) - 1:\n",
        "            curr_line = cleaned_lines[i]\n",
        "            next_line = cleaned_lines[i + 1]\n",
        "\n",
        "            if len(curr_line.split()) <= 3 and len(next_line.split()) <= 3:\n",
        "                if re.search(r'\\b(yes|no|applause|thank)\\b', curr_line.lower()) and \\\n",
        "                   re.search(r'\\b(yes|no|applause|thank)\\b', next_line.lower()):\n",
        "                    # Skip both lines - they're likely audience responses\n",
        "                    skip_next = True\n",
        "                    continue\n",
        "\n",
        "        final_lines.append(cleaned_lines[i])\n",
        "\n",
        "    # Join the cleaned lines\n",
        "    cleaned_text = ' '.join(final_lines)\n",
        "\n",
        "    # Final regex cleanups\n",
        "    # Remove duplicate Trump mentions\n",
        "    cleaned_text = re.sub(r'(Trump\\s*){3,}', 'Trump ', cleaned_text)\n",
        "\n",
        "    # Remove \"we will\" / \"we are\" repetitions\n",
        "    cleaned_text = re.sub(r'(we will\\s*){2,}', 'we will ', cleaned_text)\n",
        "    cleaned_text = re.sub(r'(we are\\s*){2,}', 'we are ', cleaned_text)\n",
        "\n",
        "    # Remove \"we are not going back\" repetitions\n",
        "    cleaned_text = re.sub(r'(we are not going back\\.*\\s*){2,}', 'we are not going back. ', cleaned_text)\n",
        "\n",
        "    # Clean up any resulting double spaces\n",
        "    cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text)\n",
        "\n",
        "    return cleaned_text.strip()\n",
        "\n",
        "def test_chunker (speech_text, threshold=0.6, min_sentences=5, target_chunk_size=2000, max_chunk_size=4000):\n",
        "    \"\"\"\n",
        "    Create semantic chunks from campaign speech text for pentad analysis,\n",
        "    optimized for LLM processing with larger chunk sizes.\n",
        "\n",
        "    Args:\n",
        "        speech_text (str): Full campaign speech text\n",
        "        threshold (float): Cosine similarity threshold (0-1)\n",
        "        min_sentences (int): Minimum sentences before considering a chunk complete\n",
        "        target_chunk_size (int): Target character size for chunks (optimal for LLM)\n",
        "        max_chunk_size (int): Maximum character size for chunks (LLM constraint)\n",
        "\n",
        "    Returns:\n",
        "        list: List of semantically coherent text chunks\n",
        "    \"\"\"\n",
        "    # Simple sentence splitting\n",
        "    sentences = [s.strip() for s in speech_text.replace('\\n', ' ').split('. ')]\n",
        "    sentences = [s + '.' if not s.endswith('.') else s for s in sentences if s]\n",
        "\n",
        "    # Load model for embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Generate embeddings for all sentences\n",
        "    embeddings = model.encode(sentences)\n",
        "\n",
        "    # Initialize variables\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_chunk_embeddings = []\n",
        "    current_chunk_chars = 0\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        sentence_chars = len(sentence)\n",
        "\n",
        "        if not current_chunk:\n",
        "            # Start a new chunk\n",
        "            current_chunk.append(sentence)\n",
        "            current_chunk_embeddings.append(embeddings[i])\n",
        "            current_chunk_chars += sentence_chars\n",
        "        else:\n",
        "            # Calculate similarity with the average of current chunk\n",
        "            avg_embedding = np.mean(current_chunk_embeddings, axis=0)\n",
        "            similarity = util.pytorch_cos_sim(embeddings[i], avg_embedding).item()\n",
        "\n",
        "            # Logic for adding sentences to chunks based on multiple criteria:\n",
        "            # 1. If very similar and below max size - add to current chunk\n",
        "            # 2. If reached target size with enough sentences - start new chunk\n",
        "            # 3. If would exceed max size - force start new chunk\n",
        "\n",
        "            if (similarity >= threshold and\n",
        "                current_chunk_chars + sentence_chars <= max_chunk_size):\n",
        "                # Add to current chunk if similar enough and within size limits\n",
        "                current_chunk.append(sentence)\n",
        "                current_chunk_embeddings.append(embeddings[i])\n",
        "                current_chunk_chars += sentence_chars\n",
        "            elif (len(current_chunk) >= min_sentences and\n",
        "                  current_chunk_chars >= target_chunk_size):\n",
        "                # Start new chunk if current chunk is big enough\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                current_chunk = [sentence]\n",
        "                current_chunk_embeddings = [embeddings[i]]\n",
        "                current_chunk_chars = sentence_chars\n",
        "            elif current_chunk_chars + sentence_chars > max_chunk_size:\n",
        "                # Force start new chunk if would exceed max size\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                current_chunk = [sentence]\n",
        "                current_chunk_embeddings = [embeddings[i]]\n",
        "                current_chunk_chars = sentence_chars\n",
        "            else:\n",
        "                # Add to current chunk even if less similar\n",
        "                current_chunk.append(sentence)\n",
        "                current_chunk_embeddings.append(embeddings[i])\n",
        "                current_chunk_chars += sentence_chars\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    # Post-processing: Combine consecutive chunks if they're small\n",
        "    i = 0\n",
        "    while i < len(chunks) - 1:\n",
        "        combined_size = len(chunks[i]) + len(chunks[i+1]) + 1  # +1 for space\n",
        "        if combined_size <= target_chunk_size:\n",
        "            chunks[i] = chunks[i] + ' ' + chunks[i+1]\n",
        "            chunks.pop(i+1)\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### script to transcribe single speaking event saved in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jg18iP0yhsQR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_event(row):\n",
        "    \"\"\"Process a single event from your DataFrame\"\"\"\n",
        "    if pd.isna(row['Link']) or 'youtube.com' not in row['Link']:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Convert time to seconds\n",
        "    start_seconds = pd.to_timedelta(row['Start Time']).total_seconds() if row['Start Time'] else 0\n",
        "    end_seconds = pd.to_timedelta(row['End Time']).total_seconds() if row['End Time'] else None\n",
        "    duration = end_seconds - start_seconds if end_seconds else None\n",
        "\n",
        "    # Download and transcribe\n",
        "    download_audio(row['Link'], start_seconds)\n",
        "    transcript_data, _ = new_transcribe_audio(start_seconds)\n",
        "\n",
        "    # Clean and chunk\n",
        "    cleaned_text = clean_transcript(transcript_data['full_text'])\n",
        "    chunks = test_chunker(cleaned_text)\n",
        "\n",
        "    # Create rows for DataFrame\n",
        "    data = []\n",
        "\n",
        "    # Add full text\n",
        "    data.append({\n",
        "        'date': row['Date'],\n",
        "        'type': row['Type'],\n",
        "        'description': row['Description'],\n",
        "        'text_type': 'full',\n",
        "        'text': cleaned_text,\n",
        "        'chunk_id': 'full',\n",
        "        'words': len(cleaned_text.split())\n",
        "    })\n",
        "\n",
        "    # Add chunks\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        data.append({\n",
        "            'date': row['Date'],\n",
        "            'type': row['Type'],\n",
        "            'description': row['Description'],\n",
        "            'text_type': 'chunk',\n",
        "            'text': chunk,\n",
        "            'chunk_id': f'chunk_{i+1}',\n",
        "            'words': len(chunk.split())\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing \n",
        "\n",
        "loading campaign event data and processing it "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lZ1SzeX2lMOA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Get the current directory where your script is located\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Create the full path to your CSV file\n",
        "path = os.path.join(current_dir, 'Kamala Acvtivity.csv')\n",
        "\n",
        "events_df = pd.read_csv(path)\n",
        "\n",
        "events_df = events_df.dropna(subset='Link')\n",
        "events_df = events_df.rename(columns = {'Start Time ': 'Start Time', 'Description ': 'Description'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check df is loaded correctly \n",
        "len(events_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c43d7eb9fba746ac85ea3c8f60e48849",
            "a887214562ad4362b0bebd02f9ff70e5",
            "2eae978a37d5456fba401c3ac2cfd281",
            "be38bf25724349a28f0754f3da59dfbb",
            "bbcba15fc61248f2addb124fc25b454f",
            "e063ddd8a4d74c38a98b347cc600c5c6",
            "bb877bc15b4f4f5fb81fb4af34eecf69",
            "0b32cae4eb3a4f55a649b9e75683bbdc",
            "0978e75e7d7140e8b5460dee56f18562",
            "70689a912f7c4359b9c245dc3d868d7e",
            "5345d5224df44d3c891dedef1a8a2db4",
            "061993bae7fd48c1a70e1b4e16974065",
            "534180673f644d21a2fd4e7f7d9cced9",
            "a47848ac8ee343e58d65552503a6121a",
            "01e96b8fc9344e16935ac7d164cbb932",
            "c04c70b97fd14050a6931f4582a5dab0",
            "0cf21065e7f04f6ea393e7205ab1856b",
            "a2d39e6b3b764f79869ccb4ecfc717a6",
            "2a6fd1e42dfd4a988191b1aa17f39481",
            "9e24a94978f5499ca4630ce752ee4e02",
            "41c5f9d942324f89a8048060f8d4ef9f",
            "a5b79e22a66641efbbfe799f22d0431c",
            "1d3e98bb1c08496c807c584d65fec5c0",
            "f58584d6c720411882e46f327f7c7f0f",
            "b9817529ffc74e74a0a1e553bdb02f3a",
            "3d45f216a7004d0c8137e22a9cd9e93a",
            "13fbf4013cf14b18a563610f6eb755cb",
            "fde2ca94fd4c4ee3aa97ef716c3d24f2",
            "ac877fd801cf497796161ea7446dd24b",
            "6833a96856cb41e1bd2d2852a63914b4",
            "a45f74baff5e4266b76466b04085e6d3",
            "9fdb6e25c778426c8f65754c79f2835a",
            "783ec1a0a7c14e1e99d3b31d6d83a63a",
            "3d1986f699004f8f8c62a761f1e2a2b9",
            "aa651f5104cf48c08be78bdfb7ea62b5",
            "6b972c7773f9422eb4d4323fc3dcb244",
            "bfbc80a22b804c5f8b500291651c13e8",
            "31e66d0502ef454a9ba5b815a15c487e",
            "c31c342be09540efb1056ad836797d4e",
            "fe19ccb814c64923852d1a38bc463a36",
            "b88cf91f9224425e88110e6e2dc011f1",
            "14729e1b330d4fb297261b42cac635c5",
            "80cbf90171e0462ba2b35907b4e2c955",
            "a5fd1774e77e4e5f8142932d846d1bc2",
            "935c670faf4945d892f0ae2df8fd4504",
            "d5f972819a7847c29ecc5fa329636cf0",
            "7ca9aefd92c944b9a120f06ea334b675",
            "38167e3d416e4863aaa69fb0936c17d5",
            "fa30b0d2a09c4a62a54a629ec46aa660",
            "80642c18a20f400f82977005f4718a4b",
            "9f84cc60330449e7a0941ba2f2d93649",
            "7d4b2787b26e4f0d9bdc5acd3ed4779e",
            "fa3e622aae52401d8b00174e682fcd87",
            "1a9625ca92d84fadb111b4ca64408582",
            "9ac9735d6d16401e9e58042cf415186a",
            "e42f2b3e012f402aae40ffc63aaa94db",
            "cc71300d8e4940f581c2f1d8b05f5fd7",
            "680378ca40984e879894417bf11a5ace",
            "e486aa88820b4ae99ee2e853e0054116",
            "34ed50d452de4c33bb5621930e2932c2",
            "55ba4a2aa8d645f99ee0443b46961e9c",
            "325261339dbb4c3baae75c0243b97894",
            "0a5cf28baf1640c7a6e0c35fbb6a6bef",
            "32e2383eaa954d849be8887c7c0e2dab",
            "9447408cf5ae4e93ab4499284e769bae",
            "16fbf1be801b4e7cb566cc9058ca2cbd",
            "0a495f19511049168893230f4ebdeceb",
            "31ccb03636994e2d8f90dc9f21d24288",
            "49d1bf1f43c04291995858cd501edcc8",
            "dd773cdea9ac4927975f0b9279a08878",
            "f0fd25ed81cd43989b46b29e33aac2c1",
            "6547ab549371435aaf3f7fc82e80e055",
            "074aca510bba49609b8ee88b2fcfe271",
            "ac02ab11bc8e45c7939d461ba997459d",
            "385b0d651cb14e4bb3b691839dd86e57",
            "44e4166108d9463691f64b19d0958f6d",
            "f454be89fe3c49fc86c4f4e5388d3c99",
            "868b4b29b39d442b8af5534e7ccc205c",
            "00c5634db1fb409ea3f1f5985f133692",
            "aa9f99f095b44ce6bdff520e250910e1",
            "cca7a12ff04e4157aadc162a5877c7d9",
            "379fee9b3fa442a8b4a3d3df72cd6ceb",
            "b4ef744095724f2787f080f99fe7c137",
            "128b870d01fc46939742e7294e2c518b",
            "c6a0138c9e634b759ad8867da4af5fc5",
            "69c426dfbe964241a78dcf40f696ad5a",
            "a6b6e461732e4e3ea91b7c7988c12cad",
            "c9c61542435a4c08b2fcd11b0842adae",
            "f2ec1099ec064a9391b2c1dfe16ae517",
            "a678825c0cf04510b6386f014fbb8435",
            "9426cf71fdbc464798aabb7bff58f7f9",
            "4e9d93e62e8245c3989abef76ae7016b",
            "d30c30d75c2f44488b8db9d1afa55138",
            "60eeee1a20ed478d91b1f5a9e419a4dc",
            "d4b3f58c881c4126b365affe895cc09a",
            "1ab5f9cd5dde4b228158589c0964c537",
            "471a965f07ce4c108fe86d40141a7a30",
            "e4b4c421f0874d4b85b9d6cb9290230d",
            "a7fc79ab819d444984b2e59a3d261eb5",
            "61e0f3c375934d549fa21a9d509d3689",
            "6522256761bc4f1c80c0635a08b2092a",
            "1d0103bbe17f43c4992903558ef0eacb",
            "f694a0297f3b49688d8c498632f26ba4",
            "ea543f542f224aeab710cf938d019879",
            "c184fdae342444f3a42859c74194e07d",
            "4f22c20678d04521826145ab8e06e997",
            "b52bef3b092d4d328ed17b7fd98c947e",
            "ae7df6d4e33442f7b406cead0f3e1d32",
            "b2e50532e39a4aba80e2c0d24377d395",
            "00140994568049dd801a8dfb4333bebf",
            "91f8dcdef0ad4d71a9bf89e46a10e26a",
            "9c53cc5d1bb1433a80cc0e4e4ba7adb3",
            "f47a01cd572d4342a0e359f74542a7fb",
            "98d0da70fa7f46e2a6e8a366d399a74a",
            "31cfaf4abd9c4bd78bceadcbdf03ce52",
            "a24979ac4ecc4e32b6bc68f3b0a86285",
            "a3ff45ea9d7942abb6baa50ddd7ff3f4",
            "4098339497fe411d9465c174831c308d",
            "89b451f0350243ad97447f0ba13c540b",
            "51afd5a3515147109548b5363af07048",
            "ee31ae0cf45542b38eec4ee06b23f4ca"
          ]
        },
        "id": "dM3kj0GkhylQ",
        "outputId": "f0ea9eb8-bd47-46c9-b846-50622630f73d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=JPQpRRPT5BU\n",
            "[youtube] JPQpRRPT5BU: Downloading webpage\n",
            "[youtube] JPQpRRPT5BU: Downloading tv client config\n",
            "[youtube] JPQpRRPT5BU: Downloading player 9a279502-main\n",
            "[youtube] JPQpRRPT5BU: Downloading tv player API JSON\n",
            "[youtube] JPQpRRPT5BU: Downloading ios player API JSON\n",
            "[youtube] JPQpRRPT5BU: Downloading m3u8 information\n",
            "[info] JPQpRRPT5BU: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   17.27MiB in 00:00:00 at 28.40MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 108952/108952 [01:22<00:00, 1319.54frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-07-23 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=_lpYc-Ww8j4\n",
            "[youtube] _lpYc-Ww8j4: Downloading webpage\n",
            "[youtube] _lpYc-Ww8j4: Downloading tv client config\n",
            "[youtube] _lpYc-Ww8j4: Downloading player 9a279502-main\n",
            "[youtube] _lpYc-Ww8j4: Downloading tv player API JSON\n",
            "[youtube] _lpYc-Ww8j4: Downloading ios player API JSON\n",
            "[youtube] _lpYc-Ww8j4: Downloading m3u8 information\n",
            "[info] _lpYc-Ww8j4: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   18.98MiB in 00:00:01 at 14.99MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 121000/123077 [01:11<00:01, 1148.23frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "100%|██████████| 123077/123077 [01:15<00:00, 1627.27frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-07-30 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=_VNi5Pe7zZM&ab_channel=TheBidenWhiteHouse\n",
            "[youtube] _VNi5Pe7zZM: Downloading webpage\n",
            "[youtube] _VNi5Pe7zZM: Downloading tv client config\n",
            "[youtube] _VNi5Pe7zZM: Downloading player 9a279502-main\n",
            "[youtube] _VNi5Pe7zZM: Downloading tv player API JSON\n",
            "[youtube] _VNi5Pe7zZM: Downloading ios player API JSON\n",
            "[youtube] _VNi5Pe7zZM: Downloading m3u8 information\n",
            "[info] _VNi5Pe7zZM: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   11.95MiB in 00:00:01 at 11.84MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99256/99256 [01:00<00:00, 1634.91frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-07-31 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=2dU9oEGJ4zM&ab_channel=WFAA\n",
            "[youtube] 2dU9oEGJ4zM: Downloading webpage\n",
            "[youtube] 2dU9oEGJ4zM: Downloading tv client config\n",
            "[youtube] 2dU9oEGJ4zM: Downloading player 9a279502-main\n",
            "[youtube] 2dU9oEGJ4zM: Downloading tv player API JSON\n",
            "[youtube] 2dU9oEGJ4zM: Downloading ios player API JSON\n",
            "[youtube] 2dU9oEGJ4zM: Downloading m3u8 information\n",
            "[info] 2dU9oEGJ4zM: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   18.70MiB in 00:00:03 at 6.12MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157574/157574 [04:34<00:00, 574.21frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-07 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=5_xPGvP62-A\n",
            "[youtube] 5_xPGvP62-A: Downloading webpage\n",
            "[youtube] 5_xPGvP62-A: Downloading tv client config\n",
            "[youtube] 5_xPGvP62-A: Downloading player 9a279502-main\n",
            "[youtube] 5_xPGvP62-A: Downloading tv player API JSON\n",
            "[youtube] 5_xPGvP62-A: Downloading ios player API JSON\n",
            "[youtube] 5_xPGvP62-A: Downloading m3u8 information\n",
            "[info] 5_xPGvP62-A: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   20.82MiB in 00:00:01 at 10.68MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 137800/137957 [04:50<00:00, 451.24frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "100%|█████████▉| 137800/137957 [05:02<00:00, 451.24frames/s]Got start time outside of audio boundary\n",
            "100%|██████████| 137957/137957 [05:02<00:00, 455.59frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-07 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=07A6iRmiixk&ab_channel=WFAA\n",
            "[youtube] 07A6iRmiixk: Downloading webpage\n",
            "[youtube] 07A6iRmiixk: Downloading tv client config\n",
            "[youtube] 07A6iRmiixk: Downloading player 9a279502-main\n",
            "[youtube] 07A6iRmiixk: Downloading tv player API JSON\n",
            "[youtube] 07A6iRmiixk: Downloading ios player API JSON\n",
            "[youtube] 07A6iRmiixk: Downloading m3u8 information\n",
            "[info] 07A6iRmiixk: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   18.87MiB in 00:00:03 at 6.05MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 147354/147354 [01:41<00:00, 1451.66frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-08 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=H8rizxQqQR0&ab_channel=ABC15Arizona\n",
            "[youtube] H8rizxQqQR0: Downloading webpage\n",
            "[youtube] H8rizxQqQR0: Downloading tv client config\n",
            "[youtube] H8rizxQqQR0: Downloading player 9a279502-main\n",
            "[youtube] H8rizxQqQR0: Downloading tv player API JSON\n",
            "[youtube] H8rizxQqQR0: Downloading ios player API JSON\n",
            "[youtube] H8rizxQqQR0: Downloading m3u8 information\n",
            "[info] H8rizxQqQR0: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of  114.54MiB in 00:00:20 at 5.72MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 876407/879407 [07:46<00:01, 1880.60frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-09 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=GLYhhwf-4yo\n",
            "[youtube] GLYhhwf-4yo: Downloading webpage\n",
            "[youtube] GLYhhwf-4yo: Downloading tv client config\n",
            "[youtube] GLYhhwf-4yo: Downloading player 9a279502-main\n",
            "[youtube] GLYhhwf-4yo: Downloading tv player API JSON\n",
            "[youtube] GLYhhwf-4yo: Downloading ios player API JSON\n",
            "[youtube] GLYhhwf-4yo: Downloading m3u8 information\n",
            "[info] GLYhhwf-4yo: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   25.27MiB in 00:00:01 at 16.78MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169279/169279 [01:29<00:00, 1889.17frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-10 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=RR9K55Tvg90&ab_channel=TheBidenWhiteHouse\n",
            "[youtube] RR9K55Tvg90: Downloading webpage\n",
            "[youtube] RR9K55Tvg90: Downloading tv client config\n",
            "[youtube] RR9K55Tvg90: Downloading player 753b1819-main\n",
            "[youtube] RR9K55Tvg90: Downloading tv player API JSON\n",
            "[youtube] RR9K55Tvg90: Downloading ios player API JSON\n",
            "[youtube] RR9K55Tvg90: Downloading m3u8 information\n",
            "[info] RR9K55Tvg90: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   25.72MiB in 00:00:04 at 5.53MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 214732/214732 [04:08<00:00, 865.01frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-15 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=NaQ5KGwAox0&ab_channel=MilwaukeeJournalSentinel\n",
            "[youtube] NaQ5KGwAox0: Downloading webpage\n",
            "[youtube] NaQ5KGwAox0: Downloading tv client config\n",
            "[youtube] NaQ5KGwAox0: Downloading player 9a279502-main\n",
            "[youtube] NaQ5KGwAox0: Downloading tv player API JSON\n",
            "[youtube] NaQ5KGwAox0: Downloading ios player API JSON\n",
            "[youtube] NaQ5KGwAox0: Downloading m3u8 information\n",
            "[info] NaQ5KGwAox0: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   46.65MiB in 00:00:12 at 3.87MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 432489/432489 [07:17<00:00, 988.12frames/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-20 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Kn7EPojdKT0\n",
            "[youtube] Kn7EPojdKT0: Downloading webpage\n",
            "[youtube] Kn7EPojdKT0: Downloading tv client config\n",
            "[youtube] Kn7EPojdKT0: Downloading player 9a279502-main\n",
            "[youtube] Kn7EPojdKT0: Downloading tv player API JSON\n",
            "[youtube] Kn7EPojdKT0: Downloading ios player API JSON\n",
            "[youtube] Kn7EPojdKT0: Downloading m3u8 information\n",
            "[info] Kn7EPojdKT0: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   47.42MiB in 00:00:02 at 15.81MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313374/313374 [03:35<00:00, 1456.01frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-22 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=60sVKUwuF5M&ab_channel=FOX5Atlanta\n",
            "[youtube] 60sVKUwuF5M: Downloading webpage\n",
            "[youtube] 60sVKUwuF5M: Downloading tv client config\n",
            "[youtube] 60sVKUwuF5M: Downloading player 9a279502-main\n",
            "[youtube] 60sVKUwuF5M: Downloading tv player API JSON\n",
            "[youtube] 60sVKUwuF5M: Downloading ios player API JSON\n",
            "[youtube] 60sVKUwuF5M: Downloading m3u8 information\n",
            "[info] 60sVKUwuF5M: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   19.88MiB in 00:00:03 at 6.10MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 124751/124751 [01:10<00:00, 1778.21frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-08-29 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=vVW6efTCM8M&ab_channel=KamalaHarris\n",
            "[youtube] vVW6efTCM8M: Downloading webpage\n",
            "[youtube] vVW6efTCM8M: Downloading tv client config\n",
            "[youtube] vVW6efTCM8M: Downloading player 9a279502-main\n",
            "[youtube] vVW6efTCM8M: Downloading tv player API JSON\n",
            "[youtube] vVW6efTCM8M: Downloading ios player API JSON\n",
            "[youtube] vVW6efTCM8M: Downloading m3u8 information\n",
            "[info] vVW6efTCM8M: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   19.60MiB in 00:00:02 at 6.86MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 157001/172001 [01:49<00:10, 1437.32frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-02 - Rally \n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=2M0fHti7DZI&ab_channel=KamalaHarris\n",
            "[youtube] 2M0fHti7DZI: Downloading webpage\n",
            "[youtube] 2M0fHti7DZI: Downloading tv client config\n",
            "[youtube] 2M0fHti7DZI: Downloading player 9a279502-main\n",
            "[youtube] 2M0fHti7DZI: Downloading tv player API JSON\n",
            "[youtube] 2M0fHti7DZI: Downloading ios player API JSON\n",
            "[youtube] 2M0fHti7DZI: Downloading m3u8 information\n",
            "[info] 2M0fHti7DZI: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   35.90MiB in 00:00:03 at 10.29MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 297300/299001 [04:09<00:01, 1124.10frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "100%|██████████| 299001/299001 [04:14<00:00, 1176.39frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-02 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=TAlEsoHtmGg&ab_channel=FOX26Houston\n",
            "[youtube] TAlEsoHtmGg: Downloading webpage\n",
            "[youtube] TAlEsoHtmGg: Downloading tv client config\n",
            "[youtube] TAlEsoHtmGg: Downloading player 9a279502-main\n",
            "[youtube] TAlEsoHtmGg: Downloading tv player API JSON\n",
            "[youtube] TAlEsoHtmGg: Downloading ios player API JSON\n",
            "[youtube] TAlEsoHtmGg: Downloading m3u8 information\n",
            "[info] TAlEsoHtmGg: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   22.88MiB in 00:00:02 at 7.85MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 153192/153192 [01:48<00:00, 1416.26frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-04 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=aX-uJgI3Pl8\n",
            "[youtube] aX-uJgI3Pl8: Downloading webpage\n",
            "[youtube] aX-uJgI3Pl8: Downloading tv client config\n",
            "[youtube] aX-uJgI3Pl8: Downloading player 9a279502-main\n",
            "[youtube] aX-uJgI3Pl8: Downloading tv player API JSON\n",
            "[youtube] aX-uJgI3Pl8: Downloading ios player API JSON\n",
            "[youtube] aX-uJgI3Pl8: Downloading m3u8 information\n",
            "[info] aX-uJgI3Pl8: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   23.71MiB in 00:00:03 at 7.36MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▎| 178508/190508 [01:38<00:06, 1813.46frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-12 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=4P0JCqIjRT0&ab_channel=WFAA\n",
            "[youtube] 4P0JCqIjRT0: Downloading webpage\n",
            "[youtube] 4P0JCqIjRT0: Downloading tv client config\n",
            "[youtube] 4P0JCqIjRT0: Downloading player 9a279502-main\n",
            "[youtube] 4P0JCqIjRT0: Downloading tv player API JSON\n",
            "[youtube] 4P0JCqIjRT0: Downloading ios player API JSON\n",
            "[youtube] 4P0JCqIjRT0: Downloading m3u8 information\n",
            "[info] 4P0JCqIjRT0: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   20.22MiB in 00:00:03 at 5.43MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143218/143218 [01:59<00:00, 1202.47frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-12 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=9yzHzGYUeTQ&ab_channel=FOX4Dallas-FortWorth\n",
            "[youtube] 9yzHzGYUeTQ: Downloading webpage\n",
            "[youtube] 9yzHzGYUeTQ: Downloading tv client config\n",
            "[youtube] 9yzHzGYUeTQ: Downloading player 9a279502-main\n",
            "[youtube] 9yzHzGYUeTQ: Downloading tv player API JSON\n",
            "[youtube] 9yzHzGYUeTQ: Downloading ios player API JSON\n",
            "[youtube] 9yzHzGYUeTQ: Downloading m3u8 information\n",
            "[info] 9yzHzGYUeTQ: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   21.08MiB in 00:00:07 at 2.96MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 135589/135589 [02:22<00:00, 951.64frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-13 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=9AunRg_V078&ab_channel=6abcPhiladelphia\n",
            "[youtube] 9AunRg_V078: Downloading webpage\n",
            "[youtube] 9AunRg_V078: Downloading tv client config\n",
            "[youtube] 9AunRg_V078: Downloading player 9a279502-main\n",
            "[youtube] 9AunRg_V078: Downloading tv player API JSON\n",
            "[youtube] 9AunRg_V078: Downloading ios player API JSON\n",
            "[youtube] 9AunRg_V078: Downloading m3u8 information\n",
            "[info] 9AunRg_V078: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   11.17MiB in 00:00:00 at 16.60MiB/s  \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 67899/67899 [00:57<00:00, 1190.28frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-13 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=1A8aumdgaHY&ab_channel=FOX29Philadelphiaa\n",
            "[youtube] 1A8aumdgaHY: Downloading webpage\n",
            "[youtube] 1A8aumdgaHY: Downloading tv client config\n",
            "[youtube] 1A8aumdgaHY: Downloading player 9a279502-main\n",
            "[youtube] 1A8aumdgaHY: Downloading tv player API JSON\n",
            "[youtube] 1A8aumdgaHY: Downloading ios player API JSON\n",
            "[youtube] 1A8aumdgaHY: Downloading m3u8 information\n",
            "[info] 1A8aumdgaHY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   42.23MiB in 00:00:03 at 11.00MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 282510/282510 [04:07<00:00, 1143.42frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-17 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=kAlAsFvOGSg&ab_channel=PBSNewsHour\n",
            "[youtube] kAlAsFvOGSg: Downloading webpage\n",
            "[youtube] kAlAsFvOGSg: Downloading tv client config\n",
            "[youtube] kAlAsFvOGSg: Downloading player 9a279502-main\n",
            "[youtube] kAlAsFvOGSg: Downloading tv player API JSON\n",
            "[youtube] kAlAsFvOGSg: Downloading ios player API JSON\n",
            "[youtube] kAlAsFvOGSg: Downloading m3u8 information\n",
            "[info] kAlAsFvOGSg: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   18.69MiB in 00:00:02 at 7.27MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 147994/147994 [01:51<00:00, 1328.61frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-18 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=cIaRQPsgOzI\n",
            "[youtube] cIaRQPsgOzI: Downloading webpage\n",
            "[youtube] cIaRQPsgOzI: Downloading tv client config\n",
            "[youtube] cIaRQPsgOzI: Downloading player 9a279502-main\n",
            "[youtube] cIaRQPsgOzI: Downloading tv player API JSON\n",
            "[youtube] cIaRQPsgOzI: Downloading ios player API JSON\n",
            "[youtube] cIaRQPsgOzI: Downloading m3u8 information\n",
            "[info] cIaRQPsgOzI: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   48.28MiB in 00:00:07 at 6.87MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 387522/387522 [06:58<00:00, 925.14frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-19 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=WLoxQ44epxI\n",
            "[youtube] WLoxQ44epxI: Downloading webpage\n",
            "[youtube] WLoxQ44epxI: Downloading tv client config\n",
            "[youtube] WLoxQ44epxI: Downloading player 9a279502-main\n",
            "[youtube] WLoxQ44epxI: Downloading tv player API JSON\n",
            "[youtube] WLoxQ44epxI: Downloading ios player API JSON\n",
            "[youtube] WLoxQ44epxI: Downloading m3u8 information\n",
            "[info] WLoxQ44epxI: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   22.13MiB in 00:00:03 at 5.69MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 183952/183952 [02:41<00:00, 1140.90frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-20 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=nRkoMZB3Oq4&ab_channel=WTVCNewsChannel9\n",
            "[youtube] nRkoMZB3Oq4: Downloading webpage\n",
            "[youtube] nRkoMZB3Oq4: Downloading tv client config\n",
            "[youtube] nRkoMZB3Oq4: Downloading player 9a279502-main\n",
            "[youtube] nRkoMZB3Oq4: Downloading tv player API JSON\n",
            "[youtube] nRkoMZB3Oq4: Downloading ios player API JSON\n",
            "[youtube] nRkoMZB3Oq4: Downloading m3u8 information\n",
            "[info] nRkoMZB3Oq4: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   16.77MiB in 00:00:01 at 8.57MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 140567/140567 [01:38<00:00, 1426.29frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-20 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=-i64tqglpmA&ab_channel=WFAA\n",
            "[youtube] -i64tqglpmA: Downloading webpage\n",
            "[youtube] -i64tqglpmA: Downloading tv client config\n",
            "[youtube] -i64tqglpmA: Downloading player 9a279502-main\n",
            "[youtube] -i64tqglpmA: Downloading tv player API JSON\n",
            "[youtube] -i64tqglpmA: Downloading ios player API JSON\n",
            "[youtube] -i64tqglpmA: Downloading m3u8 information\n",
            "[info] -i64tqglpmA: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   33.32MiB in 00:00:06 at 5.39MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 237868/237868 [02:31<00:00, 1574.87frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-25 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=QeGWT7ard5U&ab_channel=KamalaHarris\n",
            "[youtube] QeGWT7ard5U: Downloading webpage\n",
            "[youtube] QeGWT7ard5U: Downloading tv client config\n",
            "[youtube] QeGWT7ard5U: Downloading player 9a279502-main\n",
            "[youtube] QeGWT7ard5U: Downloading tv player API JSON\n",
            "[youtube] QeGWT7ard5U: Downloading ios player API JSON\n",
            "[youtube] QeGWT7ard5U: Downloading m3u8 information\n",
            "[info] QeGWT7ard5U: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   22.33MiB in 00:00:02 at 8.27MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 180300/180300 [01:53<00:00, 1585.29frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-27 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=bzThwqnQJDY&ab_channel=ALLTHESMOKE\n",
            "[youtube] bzThwqnQJDY: Downloading webpage\n",
            "[youtube] bzThwqnQJDY: Downloading tv client config\n",
            "[youtube] bzThwqnQJDY: Downloading player 9a279502-main\n",
            "[youtube] bzThwqnQJDY: Downloading tv player API JSON\n",
            "[youtube] bzThwqnQJDY: Downloading ios player API JSON\n",
            "[youtube] bzThwqnQJDY: Downloading m3u8 information\n",
            "[info] bzThwqnQJDY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   38.83MiB in 00:00:01 at 21.57MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 285514/285514 [05:42<00:00, 832.89frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-09-30 - Podcast\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=1JPBKKfc3Ok&ab_channel=KamalaHarris\n",
            "[youtube] 1JPBKKfc3Ok: Downloading webpage\n",
            "[youtube] 1JPBKKfc3Ok: Downloading tv client config\n",
            "[youtube] 1JPBKKfc3Ok: Downloading player 9a279502-main\n",
            "[youtube] 1JPBKKfc3Ok: Downloading tv player API JSON\n",
            "[youtube] 1JPBKKfc3Ok: Downloading ios player API JSON\n",
            "[youtube] 1JPBKKfc3Ok: Downloading m3u8 information\n",
            "[info] 1JPBKKfc3Ok: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   37.10MiB in 00:00:02 at 14.22MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 285624/291624 [03:04<00:03, 1546.97frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-03 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=gVzjoxj-ZQQ&ab_channel=KamalaHarris\n",
            "[youtube] gVzjoxj-ZQQ: Downloading webpage\n",
            "[youtube] gVzjoxj-ZQQ: Downloading tv client config\n",
            "[youtube] gVzjoxj-ZQQ: Downloading player 753b1819-main\n",
            "[youtube] gVzjoxj-ZQQ: Downloading tv player API JSON\n",
            "[youtube] gVzjoxj-ZQQ: Downloading ios player API JSON\n",
            "[youtube] gVzjoxj-ZQQ: Downloading m3u8 information\n",
            "[info] gVzjoxj-ZQQ: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   45.29MiB in 00:00:03 at 14.80MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 361304/364304 [03:17<00:01, 1829.75frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-04 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=a4mEKdROVOo&ab_channel=KamalaHarris\n",
            "[youtube] a4mEKdROVOo: Downloading webpage\n",
            "[youtube] a4mEKdROVOo: Downloading tv client config\n",
            "[youtube] a4mEKdROVOo: Downloading player 753b1819-main\n",
            "[youtube] a4mEKdROVOo: Downloading tv player API JSON\n",
            "[youtube] a4mEKdROVOo: Downloading ios player API JSON\n",
            "[youtube] a4mEKdROVOo: Downloading m3u8 information\n",
            "[info] a4mEKdROVOo: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   17.48MiB in 00:00:01 at 12.40MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 132856/132856 [01:27<00:00, 1524.56frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-04 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=dwf393HK5YQ&ab_channel=PBSNewsHour\n",
            "[youtube] dwf393HK5YQ: Downloading webpage\n",
            "[youtube] dwf393HK5YQ: Downloading tv client config\n",
            "[youtube] dwf393HK5YQ: Downloading player 9a279502-main\n",
            "[youtube] dwf393HK5YQ: Downloading tv player API JSON\n",
            "[youtube] dwf393HK5YQ: Downloading ios player API JSON\n",
            "[youtube] dwf393HK5YQ: Downloading m3u8 information\n",
            "[info] dwf393HK5YQ: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of    5.29MiB in 00:00:01 at 3.35MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: Nynorsk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 33505/36505 [00:08<00:00, 3959.63frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-05 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=JRYG3AP2ARs&ab_channel=C-SPAN\n",
            "[youtube] JRYG3AP2ARs: Downloading webpage\n",
            "[youtube] JRYG3AP2ARs: Downloading tv client config\n",
            "[youtube] JRYG3AP2ARs: Downloading player 753b1819-main\n",
            "[youtube] JRYG3AP2ARs: Downloading tv player API JSON\n",
            "[youtube] JRYG3AP2ARs: Downloading ios player API JSON\n",
            "[youtube] JRYG3AP2ARs: Downloading m3u8 information\n",
            "[info] JRYG3AP2ARs: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of    5.23MiB in 00:00:01 at 5.17MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 33188/33188 [00:21<00:00, 1573.00frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-07 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=TJys7OVH24E&ab_channel=60Minutes\n",
            "[youtube] TJys7OVH24E: Downloading webpage\n",
            "[youtube] TJys7OVH24E: Downloading tv client config\n",
            "[youtube] TJys7OVH24E: Downloading player 9a279502-main\n",
            "[youtube] TJys7OVH24E: Downloading tv player API JSON\n",
            "[youtube] TJys7OVH24E: Downloading ios player API JSON\n",
            "[youtube] TJys7OVH24E: Downloading m3u8 information\n",
            "[info] TJys7OVH24E: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   15.52MiB in 00:00:00 at 22.06MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 124838/124931 [01:50<00:00, 1134.72frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-07 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=hO08k6s4kpM&ab_channel=TheSun\n",
            "[youtube] hO08k6s4kpM: Downloading webpage\n",
            "[youtube] hO08k6s4kpM: Downloading tv client config\n",
            "[youtube] hO08k6s4kpM: Downloading player 753b1819-main\n",
            "[youtube] hO08k6s4kpM: Downloading tv player API JSON\n",
            "[youtube] hO08k6s4kpM: Downloading ios player API JSON\n",
            "[youtube] hO08k6s4kpM: Downloading m3u8 information\n",
            "[info] hO08k6s4kpM: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   53.62MiB in 00:00:05 at 9.07MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 476877/476877 [02:31<00:00, 3144.04frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-10 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=T3KR-jtwKTM&ab_channel=PBSNewsHour\n",
            "[youtube] T3KR-jtwKTM: Downloading webpage\n",
            "[youtube] T3KR-jtwKTM: Downloading tv client config\n",
            "[youtube] T3KR-jtwKTM: Downloading player 9a279502-main\n",
            "[youtube] T3KR-jtwKTM: Downloading tv player API JSON\n",
            "[youtube] T3KR-jtwKTM: Downloading ios player API JSON\n",
            "[youtube] T3KR-jtwKTM: Downloading m3u8 information\n",
            "[info] T3KR-jtwKTM: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   14.33MiB in 00:00:01 at 7.40MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103505/103505 [01:20<00:00, 1293.12frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-11 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=XoRviMMWXx4&ab_channel=KamalaHarris\n",
            "[youtube] XoRviMMWXx4: Downloading webpage\n",
            "[youtube] XoRviMMWXx4: Downloading tv client config\n",
            "[youtube] XoRviMMWXx4: Downloading player 9a279502-main\n",
            "[youtube] XoRviMMWXx4: Downloading tv player API JSON\n",
            "[youtube] XoRviMMWXx4: Downloading ios player API JSON\n",
            "[youtube] XoRviMMWXx4: Downloading m3u8 information\n",
            "[info] XoRviMMWXx4: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   61.20MiB in 00:00:03 at 19.65MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: Khmer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 462002/462002 [14:57<00:00, 514.79frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-14 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=5WWnKBnHAP8&ab_channel=THESHADEROOM\n",
            "[youtube] 5WWnKBnHAP8: Downloading webpage\n",
            "[youtube] 5WWnKBnHAP8: Downloading tv client config\n",
            "[youtube] 5WWnKBnHAP8: Downloading player 9a279502-main\n",
            "[youtube] 5WWnKBnHAP8: Downloading tv player API JSON\n",
            "[youtube] 5WWnKBnHAP8: Downloading ios player API JSON\n",
            "[youtube] 5WWnKBnHAP8: Downloading m3u8 information\n",
            "[info] 5WWnKBnHAP8: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   30.82MiB in 00:00:02 at 11.77MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 140484/140484 [02:18<00:00, 1017.01frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-14 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=JyPSMeWU9Ms&ab_channel=PCNTV\n",
            "[youtube] JyPSMeWU9Ms: Downloading webpage\n",
            "[youtube] JyPSMeWU9Ms: Downloading tv client config\n",
            "[youtube] JyPSMeWU9Ms: Downloading player 9a279502-main\n",
            "[youtube] JyPSMeWU9Ms: Downloading tv player API JSON\n",
            "[youtube] JyPSMeWU9Ms: Downloading ios player API JSON\n",
            "[youtube] JyPSMeWU9Ms: Downloading m3u8 information\n",
            "[info] JyPSMeWU9Ms: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   40.24MiB in 00:00:03 at 10.99MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 324633/339633 [03:10<00:08, 1702.96frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-16 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=lCX48rn2WOA&ab_channel=WFAA\n",
            "[youtube] lCX48rn2WOA: Downloading webpage\n",
            "[youtube] lCX48rn2WOA: Downloading tv client config\n",
            "[youtube] lCX48rn2WOA: Downloading player 9a279502-main\n",
            "[youtube] lCX48rn2WOA: Downloading tv player API JSON\n",
            "[youtube] lCX48rn2WOA: Downloading ios player API JSON\n",
            "[youtube] lCX48rn2WOA: Downloading m3u8 information\n",
            "[info] lCX48rn2WOA: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   25.21MiB in 00:00:04 at 5.38MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 163613/163613 [01:41<00:00, 1619.51frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-17 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=EziLtK2KOdU&ab_channel=WFAA\n",
            "[youtube] EziLtK2KOdU: Downloading webpage\n",
            "[youtube] EziLtK2KOdU: Downloading tv client config\n",
            "[youtube] EziLtK2KOdU: Downloading player 9a279502-main\n",
            "[youtube] EziLtK2KOdU: Downloading tv player API JSON\n",
            "[youtube] EziLtK2KOdU: Downloading ios player API JSON\n",
            "[youtube] EziLtK2KOdU: Downloading m3u8 information\n",
            "[info] EziLtK2KOdU: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   21.73MiB in 00:00:04 at 5.07MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 168079/168079 [01:39<00:00, 1684.82frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-17 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=E1UtJv8ZFBk&ab_channel=PBSNewsHour\n",
            "[youtube] E1UtJv8ZFBk: Downloading webpage\n",
            "[youtube] E1UtJv8ZFBk: Downloading tv client config\n",
            "[youtube] E1UtJv8ZFBk: Downloading player 9a279502-main\n",
            "[youtube] E1UtJv8ZFBk: Downloading tv player API JSON\n",
            "[youtube] E1UtJv8ZFBk: Downloading ios player API JSON\n",
            "[youtube] E1UtJv8ZFBk: Downloading m3u8 information\n",
            "[info] E1UtJv8ZFBk: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   18.69MiB in 00:00:03 at 5.77MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 165500/165500 [01:54<00:00, 1447.50frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-18 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=V7Qq1mNIYrU&ab_channel=KamalaHarris\n",
            "[youtube] V7Qq1mNIYrU: Downloading webpage\n",
            "[youtube] V7Qq1mNIYrU: Downloading tv client config\n",
            "[youtube] V7Qq1mNIYrU: Downloading player 9a279502-main\n",
            "[youtube] V7Qq1mNIYrU: Downloading tv player API JSON\n",
            "[youtube] V7Qq1mNIYrU: Downloading ios player API JSON\n",
            "[youtube] V7Qq1mNIYrU: Downloading m3u8 information\n",
            "[info] V7Qq1mNIYrU: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   29.43MiB in 00:00:03 at 7.41MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 231192/234192 [03:35<00:02, 1074.59frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-18 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=rbvyoFnsz0A&ab_channel=KamalaHarris\n",
            "[youtube] rbvyoFnsz0A: Downloading webpage\n",
            "[youtube] rbvyoFnsz0A: Downloading tv client config\n",
            "[youtube] rbvyoFnsz0A: Downloading player 9a279502-main\n",
            "[youtube] rbvyoFnsz0A: Downloading tv player API JSON\n",
            "[youtube] rbvyoFnsz0A: Downloading ios player API JSON\n",
            "[youtube] rbvyoFnsz0A: Downloading m3u8 information\n",
            "[info] rbvyoFnsz0A: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   63.67MiB in 00:00:09 at 6.39MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 465499/465499 [01:32<00:00, 5016.43frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-19 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DqvCQPIt1M8&ab_channel=WFAA\n",
            "[youtube] DqvCQPIt1M8: Downloading webpage\n",
            "[youtube] DqvCQPIt1M8: Downloading tv client config\n",
            "[youtube] DqvCQPIt1M8: Downloading player 9a279502-main\n",
            "[youtube] DqvCQPIt1M8: Downloading tv player API JSON\n",
            "[youtube] DqvCQPIt1M8: Downloading ios player API JSON\n",
            "[youtube] DqvCQPIt1M8: Downloading m3u8 information\n",
            "[info] DqvCQPIt1M8: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of    4.76MiB in 00:00:00 at 8.40MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40345/40345 [00:34<00:00, 1181.28frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-19 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=rBKvZI0AB_I&ab_channel=WAAY31News\n",
            "[youtube] rBKvZI0AB_I: Downloading webpage\n",
            "[youtube] rBKvZI0AB_I: Downloading tv client config\n",
            "[youtube] rBKvZI0AB_I: Downloading player 9a279502-main\n",
            "[youtube] rBKvZI0AB_I: Downloading tv player API JSON\n",
            "[youtube] rBKvZI0AB_I: Downloading ios player API JSON\n",
            "[youtube] rBKvZI0AB_I: Downloading m3u8 information\n",
            "[info] rBKvZI0AB_I: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of    6.74MiB in 00:00:01 at 4.32MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49312/49312 [00:26<00:00, 1828.33frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-20 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=KVYbcRhOXQQ&ab_channel=WFAA\n",
            "[youtube] KVYbcRhOXQQ: Downloading webpage\n",
            "[youtube] KVYbcRhOXQQ: Downloading tv client config\n",
            "[youtube] KVYbcRhOXQQ: Downloading player 9a279502-main\n",
            "[youtube] KVYbcRhOXQQ: Downloading tv player API JSON\n",
            "[youtube] KVYbcRhOXQQ: Downloading ios player API JSON\n",
            "[youtube] KVYbcRhOXQQ: Downloading m3u8 information\n",
            "[info] KVYbcRhOXQQ: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   13.96MiB in 00:00:01 at 13.56MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 111178/111178 [01:10<00:00, 1571.62frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-20 - Event\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=XturwvZjc_E&ab_channel=KamalaHarris\n",
            "[youtube] XturwvZjc_E: Downloading webpage\n",
            "[youtube] XturwvZjc_E: Downloading tv client config\n",
            "[youtube] XturwvZjc_E: Downloading player 9a279502-main\n",
            "[youtube] XturwvZjc_E: Downloading tv player API JSON\n",
            "[youtube] XturwvZjc_E: Downloading ios player API JSON\n",
            "[youtube] XturwvZjc_E: Downloading m3u8 information\n",
            "[info] XturwvZjc_E: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   47.41MiB in 00:00:04 at 10.71MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▎ | 291002/348002 [06:11<01:12, 782.57frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-21 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=LVgFrlwsUoI&ab_channel=KamalaHarris\n",
            "[youtube] LVgFrlwsUoI: Downloading webpage\n",
            "[youtube] LVgFrlwsUoI: Downloading tv client config\n",
            "[youtube] LVgFrlwsUoI: Downloading player 9a279502-main\n",
            "[youtube] LVgFrlwsUoI: Downloading tv player API JSON\n",
            "[youtube] LVgFrlwsUoI: Downloading ios player API JSON\n",
            "[youtube] LVgFrlwsUoI: Downloading m3u8 information\n",
            "[info] LVgFrlwsUoI: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   43.69MiB in 00:00:01 at 33.26MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 334696/334696 [04:43<00:00, 1181.68frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-21 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=pkM_QiEFNps&ab_channel=TheDemocrats\n",
            "[youtube] pkM_QiEFNps: Downloading webpage\n",
            "[youtube] pkM_QiEFNps: Downloading tv client config\n",
            "[youtube] pkM_QiEFNps: Downloading player 9a279502-main\n",
            "[youtube] pkM_QiEFNps: Downloading tv player API JSON\n",
            "[youtube] pkM_QiEFNps: Downloading ios player API JSON\n",
            "[youtube] pkM_QiEFNps: Downloading m3u8 information\n",
            "[info] pkM_QiEFNps: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   40.53MiB in 00:00:04 at 8.52MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 307800/317498 [01:06<00:02, 4210.52frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            " 97%|█████████▋| 308498/317498 [01:08<00:01, 4510.07frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-21 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=iO6Ta86wCDI&ab_channel=NBCNews\n",
            "[youtube] iO6Ta86wCDI: Downloading webpage\n",
            "[youtube] iO6Ta86wCDI: Downloading tv client config\n",
            "[youtube] iO6Ta86wCDI: Downloading player 9a279502-main\n",
            "[youtube] iO6Ta86wCDI: Downloading tv player API JSON\n",
            "[youtube] iO6Ta86wCDI: Downloading ios player API JSON\n",
            "[youtube] iO6Ta86wCDI: Downloading m3u8 information\n",
            "[info] iO6Ta86wCDI: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   17.09MiB in 00:00:00 at 25.78MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 131474/131474 [02:23<00:00, 917.34frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-22 - Interview\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=U3yRr0xFZZs&ab_channel=CNN\n",
            "[youtube] U3yRr0xFZZs: Downloading webpage\n",
            "[youtube] U3yRr0xFZZs: Downloading tv client config\n",
            "[youtube] U3yRr0xFZZs: Downloading player 9a279502-main\n",
            "[youtube] U3yRr0xFZZs: Downloading tv player API JSON\n",
            "[youtube] U3yRr0xFZZs: Downloading ios player API JSON\n",
            "[youtube] U3yRr0xFZZs: Downloading m3u8 information\n",
            "[info] U3yRr0xFZZs: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   30.49MiB in 00:00:01 at 19.97MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 224396/224396 [03:41<00:00, 1015.34frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-23 - Town Hall\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=4x1EXMyEGA8&ab_channel=KamalaHarris\n",
            "[youtube] 4x1EXMyEGA8: Downloading webpage\n",
            "[youtube] 4x1EXMyEGA8: Downloading tv client config\n",
            "[youtube] 4x1EXMyEGA8: Downloading player 9a279502-main\n",
            "[youtube] 4x1EXMyEGA8: Downloading tv player API JSON\n",
            "[youtube] 4x1EXMyEGA8: Downloading ios player API JSON\n",
            "[youtube] 4x1EXMyEGA8: Downloading m3u8 information\n",
            "[info] 4x1EXMyEGA8: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of  126.04MiB in 00:00:14 at 8.71MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 934444/937444 [11:58<00:02, 1300.13frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-24 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=q8p2OvDQWaY&ab_channel=WFAA\n",
            "[youtube] q8p2OvDQWaY: Downloading webpage\n",
            "[youtube] q8p2OvDQWaY: Downloading tv client config\n",
            "[youtube] q8p2OvDQWaY: Downloading player 753b1819-main\n",
            "[youtube] q8p2OvDQWaY: Downloading tv player API JSON\n",
            "[youtube] q8p2OvDQWaY: Downloading ios player API JSON\n",
            "[youtube] q8p2OvDQWaY: Downloading m3u8 information\n",
            "[info] q8p2OvDQWaY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   19.88MiB in 00:00:04 at 4.91MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 168400/168502 [11:51<00:00, 236.55frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-25 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=wnzjBjPhrHQ&ab_channel=WFAA\n",
            "[youtube] wnzjBjPhrHQ: Downloading webpage\n",
            "[youtube] wnzjBjPhrHQ: Downloading tv client config\n",
            "[youtube] wnzjBjPhrHQ: Downloading player 753b1819-main\n",
            "[youtube] wnzjBjPhrHQ: Downloading tv player API JSON\n",
            "[youtube] wnzjBjPhrHQ: Downloading ios player API JSON\n",
            "[youtube] wnzjBjPhrHQ: Downloading m3u8 information\n",
            "[info] wnzjBjPhrHQ: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   24.06MiB in 00:00:05 at 4.47MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 187100/187829 [02:21<00:00, 1245.63frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "100%|██████████| 187829/187829 [02:26<00:00, 1279.03frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-26 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=U1Qov_Hu3Ao&ab_channel=SkyNews\n",
            "[youtube] U1Qov_Hu3Ao: Downloading webpage\n",
            "[youtube] U1Qov_Hu3Ao: Downloading tv client config\n",
            "[youtube] U1Qov_Hu3Ao: Downloading player 753b1819-main\n",
            "[youtube] U1Qov_Hu3Ao: Downloading tv player API JSON\n",
            "[youtube] U1Qov_Hu3Ao: Downloading ios player API JSON\n",
            "[youtube] U1Qov_Hu3Ao: Downloading m3u8 information\n",
            "[info] U1Qov_Hu3Ao: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   13.29MiB in 00:00:02 at 4.75MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97532/97532 [01:01<00:00, 1584.15frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-27 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=H2aOx0WXNak&ab_channel=WFAA\n",
            "[youtube] H2aOx0WXNak: Downloading webpage\n",
            "[youtube] H2aOx0WXNak: Downloading tv client config\n",
            "[youtube] H2aOx0WXNak: Downloading player 753b1819-main\n",
            "[youtube] H2aOx0WXNak: Downloading tv player API JSON\n",
            "[youtube] H2aOx0WXNak: Downloading ios player API JSON\n",
            "[youtube] H2aOx0WXNak: Downloading m3u8 information\n",
            "[info] H2aOx0WXNak: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   21.26MiB in 00:00:03 at 6.48MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 145561/145561 [01:40<00:00, 1446.69frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-28 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=6G1Oou2dVdk&ab_channel=WFAA\n",
            "[youtube] 6G1Oou2dVdk: Downloading webpage\n",
            "[youtube] 6G1Oou2dVdk: Downloading tv client config\n",
            "[youtube] 6G1Oou2dVdk: Downloading player 753b1819-main\n",
            "[youtube] 6G1Oou2dVdk: Downloading tv player API JSON\n",
            "[youtube] 6G1Oou2dVdk: Downloading ios player API JSON\n",
            "[youtube] 6G1Oou2dVdk: Downloading m3u8 information\n",
            "[info] 6G1Oou2dVdk: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   23.40MiB in 00:00:02 at 8.27MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 183042/189042 [01:48<00:03, 1693.99frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-29 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=LnXPv7nVyx8&ab_channel=WFAA\n",
            "[youtube] LnXPv7nVyx8: Downloading webpage\n",
            "[youtube] LnXPv7nVyx8: Downloading tv client config\n",
            "[youtube] LnXPv7nVyx8: Downloading player 753b1819-main\n",
            "[youtube] LnXPv7nVyx8: Downloading tv player API JSON\n",
            "[youtube] LnXPv7nVyx8: Downloading ios player API JSON\n",
            "[youtube] LnXPv7nVyx8: Downloading m3u8 information\n",
            "[info] LnXPv7nVyx8: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   15.77MiB in 00:00:02 at 7.83MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 131987/131987 [01:14<00:00, 1779.46frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-30 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=GoXcbU-Xjbk&ab_channel=MilwaukeeJournalSentinel\n",
            "[youtube] GoXcbU-Xjbk: Downloading webpage\n",
            "[youtube] GoXcbU-Xjbk: Downloading tv client config\n",
            "[youtube] GoXcbU-Xjbk: Downloading player 753b1819-main\n",
            "[youtube] GoXcbU-Xjbk: Downloading tv player API JSON\n",
            "[youtube] GoXcbU-Xjbk: Downloading ios player API JSON\n",
            "[youtube] GoXcbU-Xjbk: Downloading m3u8 information\n",
            "[info] GoXcbU-Xjbk: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   17.50MiB in 00:00:02 at 8.65MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 140501/140501 [01:24<00:00, 1668.88frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-30 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=me1z4KmJqes&ab_channel=ABC33%2F40\n",
            "[youtube] me1z4KmJqes: Downloading webpage\n",
            "[youtube] me1z4KmJqes: Downloading tv client config\n",
            "[youtube] me1z4KmJqes: Downloading player 753b1819-main\n",
            "[youtube] me1z4KmJqes: Downloading tv player API JSON\n",
            "[youtube] me1z4KmJqes: Downloading ios player API JSON\n",
            "[youtube] me1z4KmJqes: Downloading m3u8 information\n",
            "[info] me1z4KmJqes: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   58.33MiB in 00:00:10 at 5.40MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 515796/530796 [03:18<00:05, 2592.21frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-30 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=TMJx0vnYY08&ab_channel=FOX29Philadelphia\n",
            "[youtube] TMJx0vnYY08: Downloading webpage\n",
            "[youtube] TMJx0vnYY08: Downloading tv client config\n",
            "[youtube] TMJx0vnYY08: Downloading player 753b1819-main\n",
            "[youtube] TMJx0vnYY08: Downloading tv player API JSON\n",
            "[youtube] TMJx0vnYY08: Downloading ios player API JSON\n",
            "[youtube] TMJx0vnYY08: Downloading m3u8 information\n",
            "[info] TMJx0vnYY08: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   60.31MiB in 00:00:05 at 10.55MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: Spanish\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 375501/378501 [02:02<00:00, 3076.01frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-31 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=_jwaT6FN1kc&ab_channel=KamalaHarris\n",
            "[youtube] _jwaT6FN1kc: Downloading webpage\n",
            "[youtube] _jwaT6FN1kc: Downloading tv client config\n",
            "[youtube] _jwaT6FN1kc: Downloading player 9a279502-main\n",
            "[youtube] _jwaT6FN1kc: Downloading tv player API JSON\n",
            "[youtube] _jwaT6FN1kc: Downloading ios player API JSON\n",
            "[youtube] _jwaT6FN1kc: Downloading m3u8 information\n",
            "[info] _jwaT6FN1kc: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of  120.16MiB in 00:00:14 at 8.43MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 869004/869004 [03:10<00:00, 4570.02frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-31 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=5YEM-fLqJV0&ab_channel=WFAA\n",
            "[youtube] 5YEM-fLqJV0: Downloading webpage\n",
            "[youtube] 5YEM-fLqJV0: Downloading tv client config\n",
            "[youtube] 5YEM-fLqJV0: Downloading player 9a279502-main\n",
            "[youtube] 5YEM-fLqJV0: Downloading tv player API JSON\n",
            "[youtube] 5YEM-fLqJV0: Downloading ios player API JSON\n",
            "[youtube] 5YEM-fLqJV0: Downloading m3u8 information\n",
            "[info] 5YEM-fLqJV0: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   18.58MiB in 00:00:01 at 10.76MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 149960/149960 [01:41<00:00, 1482.09frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-10-31 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Y3JnjDn_cwI&ab_channel=KamalaHarris\n",
            "[youtube] Y3JnjDn_cwI: Downloading webpage\n",
            "[youtube] Y3JnjDn_cwI: Downloading tv client config\n",
            "[youtube] Y3JnjDn_cwI: Downloading player 9a279502-main\n",
            "[youtube] Y3JnjDn_cwI: Downloading tv player API JSON\n",
            "[youtube] Y3JnjDn_cwI: Downloading ios player API JSON\n",
            "[youtube] Y3JnjDn_cwI: Downloading m3u8 information\n",
            "[info] Y3JnjDn_cwI: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   31.43MiB in 00:00:08 at 3.83MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 229503/229503 [04:08<00:00, 921.92frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-01 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=dCsk2aFv9A4&ab_channel=KamalaHarris\n",
            "[youtube] dCsk2aFv9A4: Downloading webpage\n",
            "[youtube] dCsk2aFv9A4: Downloading tv client config\n",
            "[youtube] dCsk2aFv9A4: Downloading player 9a279502-main\n",
            "[youtube] dCsk2aFv9A4: Downloading tv player API JSON\n",
            "[youtube] dCsk2aFv9A4: Downloading ios player API JSON\n",
            "[youtube] dCsk2aFv9A4: Downloading m3u8 information\n",
            "[info] dCsk2aFv9A4: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of  111.50MiB in 00:00:16 at 6.62MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 814005/832005 [04:38<00:06, 2924.10frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-01 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=soG-Q0f0bdY&ab_channel=TheDemocrats\n",
            "[youtube] soG-Q0f0bdY: Downloading webpage\n",
            "[youtube] soG-Q0f0bdY: Downloading tv client config\n",
            "[youtube] soG-Q0f0bdY: Downloading player 6450230e-main\n",
            "[youtube] soG-Q0f0bdY: Downloading tv player API JSON\n",
            "[youtube] soG-Q0f0bdY: Downloading ios player API JSON\n",
            "[youtube] soG-Q0f0bdY: Downloading m3u8 information\n",
            "[info] soG-Q0f0bdY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   39.60MiB in 00:00:03 at 10.14MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 285600/293500 [04:22<00:07, 1092.00frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            " 98%|█████████▊| 287500/293500 [04:26<00:05, 1078.42frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-01 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=IBWsggOdGOA&ab_channel=WFAA\n",
            "[youtube] IBWsggOdGOA: Downloading webpage\n",
            "[youtube] IBWsggOdGOA: Downloading tv client config\n",
            "[youtube] IBWsggOdGOA: Downloading player 9a279502-main\n",
            "[youtube] IBWsggOdGOA: Downloading tv player API JSON\n",
            "[youtube] IBWsggOdGOA: Downloading ios player API JSON\n",
            "[youtube] IBWsggOdGOA: Downloading m3u8 information\n",
            "[info] IBWsggOdGOA: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   19.27MiB in 00:00:01 at 11.40MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 156855/156855 [01:51<00:00, 1408.52frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-02 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=CUZ5J_t7hec&ab_channel=ABC33%2F40\n",
            "[youtube] CUZ5J_t7hec: Downloading webpage\n",
            "[youtube] CUZ5J_t7hec: Downloading tv client config\n",
            "[youtube] CUZ5J_t7hec: Downloading player 9a279502-main\n",
            "[youtube] CUZ5J_t7hec: Downloading tv player API JSON\n",
            "[youtube] CUZ5J_t7hec: Downloading ios player API JSON\n",
            "[youtube] CUZ5J_t7hec: Downloading m3u8 information\n",
            "[info] CUZ5J_t7hec: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   32.28MiB in 00:00:02 at 13.52MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 235800/242940 [02:29<00:07, 987.60frames/s] Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            " 98%|█████████▊| 236940/242940 [02:34<00:03, 1530.34frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-02 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=WRcl7Yd4gCA&ab_channel=ABC33%2F40\n",
            "[youtube] WRcl7Yd4gCA: Downloading webpage\n",
            "[youtube] WRcl7Yd4gCA: Downloading tv client config\n",
            "[youtube] WRcl7Yd4gCA: Downloading player 9a279502-main\n",
            "[youtube] WRcl7Yd4gCA: Downloading tv player API JSON\n",
            "[youtube] WRcl7Yd4gCA: Downloading ios player API JSON\n",
            "[youtube] WRcl7Yd4gCA: Downloading m3u8 information\n",
            "[info] WRcl7Yd4gCA: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   38.49MiB in 00:00:07 at 5.35MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 323084/339648 [01:44<00:06, 2608.77frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            " 96%|█████████▌| 324648/339648 [01:47<00:04, 3022.90frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-03 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=k57CWwBQ-BA&ab_channel=MilwaukeeJournalSentinel\n",
            "[youtube] k57CWwBQ-BA: Downloading webpage\n",
            "[youtube] k57CWwBQ-BA: Downloading tv client config\n",
            "[youtube] k57CWwBQ-BA: Downloading player 9a279502-main\n",
            "[youtube] k57CWwBQ-BA: Downloading tv player API JSON\n",
            "[youtube] k57CWwBQ-BA: Downloading ios player API JSON\n",
            "[youtube] k57CWwBQ-BA: Downloading m3u8 information\n",
            "[info] k57CWwBQ-BA: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   61.78MiB in 00:00:11 at 5.45MiB/s     \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 507777/507777 [04:20<00:00, 1952.07frames/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-04 - Rally\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=jHWM5pZGwIY&ab_channel=PBSNewsHour\n",
            "[youtube] jHWM5pZGwIY: Downloading webpage\n",
            "[youtube] jHWM5pZGwIY: Downloading tv client config\n",
            "[youtube] jHWM5pZGwIY: Downloading player 9a279502-main\n",
            "[youtube] jHWM5pZGwIY: Downloading tv player API JSON\n",
            "[youtube] jHWM5pZGwIY: Downloading ios player API JSON\n",
            "[youtube] jHWM5pZGwIY: Downloading m3u8 information\n",
            "[info] jHWM5pZGwIY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   93.02MiB in 00:00:08 at 10.99MiB/s    \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicho\\anaconda3\\envs\\sentence_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 751200/755003 [03:27<00:00, 5268.33frames/s]Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "Got start time outside of audio boundary\n",
            "100%|█████████▉| 752003/755003 [03:29<00:00, 3589.78frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 2024-11-04 - Rally\n",
            "Total events processed: 71\n",
            "Total chunks created: 553\n"
          ]
        }
      ],
      "source": [
        "# Process multiple events\n",
        "results = []\n",
        "\n",
        "for idx, row in events_df.iterrows():\n",
        "    try:\n",
        "        result = process_event(row)\n",
        "        if not result.empty:\n",
        "            results.append(result)\n",
        "            print(f\"Processed: {row['Date']} - {row['Type']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Combine all results\n",
        "analysis_df = pd.concat(results, ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "analysis_df.to_csv('pentad_analysis_data.csv', index=False)\n",
        "\n",
        "# Quick view\n",
        "print(f\"Total events processed: {len(analysis_df[analysis_df['text_type']=='full'])}\")\n",
        "print(f\"Total chunks created: {len(analysis_df[analysis_df['text_type']=='chunk'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "date                                                  2024-10-21\n",
              "type                                                   Interview\n",
              "description    Kamala Harris Conversation in Pennsylvania wit...\n",
              "text_type                                                   full\n",
              "text           I'm going to show you how to make a simple, si...\n",
              "chunk_id                                                    full\n",
              "words                                                       9042\n",
              "Name: 409, dtype: object"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full = analysis_df[analysis_df['text_type'] == 'full']\n",
        "test = clean_transcript(full.iloc[13].text)\n",
        "full.iloc[46]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Joe Biden and Kamala Harris were walking our picket lines when Donald Trump was crossing them. Joe Biden and Kamala Harris have led the most pro-union White House in American history. And you remember that Kamala Harris cast those deciding votes in the Senate to save millions of workers' pensions and lower costs for seniors on their prescription drugs and make the biggest investment in modern history to rebuild this country. And now Kamala Harris and our union brother Tim Walz, yes, they are ready to go even further because they believe in that future that we all want to see. Now the road to the White House goes right through our union halls. That's right, one in five voters right here in Pennsylvania is a union voter. So we are the difference maker. We have the people. We have the trust. We know how to organize. And we are ready to send Kamala Harris and Tim Walz to the White House. Are we ready? All right, I got to hear you. Are you going to get your friends registered to vote? Yes. Are you going to knock on doors? Yes. Are you going to fight every day until November 5th? Yes. That's what I thought. Because when we fight, we fight. When we fight, we fight. Yes. Thank you. Now I have the great pleasure of introducing my friend, my brother, one of the great labor leaders in this country, IBEW International President, Kenny Cooper. Let's go, Cooper. Good afternoon, brothers and sisters. Good afternoon. Thank you, brothers and sisters. Thank you, guests. And most of all, thank you, family, for being here on Labor Day. You know, it's a great honor to be in Pittsburgh, a good union town, but for me, it's really an honor to be in the House of Labor. IBEW Local 5, thank you so much for everything you do. As Liz said, I'm the international president of the IBEW, the oldest and largest electrical union in the entire world. And on behalf of 840,000 members of the IBEW, it is my true honor to get to introduce tonight the strongest, most pro-union administration ever in history in the United States, President Biden and Vice President Harris. Joe Biden made a lot of promises when he run for president in 2022 or 2020. He promised to save Americans' pension system that was a serious risk for us. He promised to help American workers that were depending on him to help save that pension. Workers who went to work every day lived by the rules, who deferred their own wages so they could retire one day with dignity and respect. He passed the Butch Lewis Act, saving the American's multi-floor pension plan. And when the Senate was all tied up, let's think about this a minute, on the rescue of America's pension plans, they were only tied up for one reason. We couldn't find a Republican senator that would vote for American workers. Why would? The vice president and Harris showed us her real colors. She stepped to the plate, casted a deciding vote to save our pension plans across America. Showing working families that Biden and Harris administration has our backs, promises made, promises kept. He pledged to rebuild our country's infrastructure, the only way to make sense was good union jobs that pays well and has health care for them and their families. Once again, promises made, promises kept. They worked together to pass the Chips and Science Act, bringing back manufacturing jobs to communities that really need them the most. Promises made, promises kept. They pledged to be true friends of labor because they understand the necessity of unions to the American worker and to the middle class. Well, Joe Biden and Kamala Harris kept every single one of those promises. Pension plan relief, the Butch Lewis Act went above and beyond our expectations. His infrastructure bills are bringing good union jobs back, much needed infrastructure across our nation, in every corner of our nation. And he's never been afraid to say the word union. Joe Biden is more than just the pro union, the most pro union president in our entire history. When he passed the torch to Kamala Harris, he ensured his pro union, pro labor legacy would continue with the next administration. Kamala Harris understands just as Joe did and Joe does now. The only way to meet the future of this great nation is by giving workers a real voice at every table, especially the most important table to every worker and every worker's family, the kitchen table. Yeah. Brothers and sisters, please join me to welcome our true friends, the president and vice president of the United States, Joe Biden and Kamala Harris. Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Thank you, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Yui, Yui went to the national president IW Abel and he said he wanted me he wanted me to get endorsed everybody thought it was crazy I literally wasn't old enough to be sworn in today I'd like to but guess what? I was unable to stuck with me they got stuck with me for the rest of my career Eric Dean the iron workers Tim Disco the bricklayer April Bowles the SEIU Lee Saunders the Rastman the great friend Jimmy Williams the painter's ally trade and his dad his dad is a really good man Mike Coleman the sheet metal worker also got some of the best elected officials America Governor Josh Shapiro is doing an incredible job the great lieutenant governor Austin Davis and one of America's best words Ed Ganey Ed you are doing a hell of a job and sir in the motto county executive I think is the hardest job in American politics everybody knows where you live and I think you can solve all the problems you don't have enough money well I tell you one thing I'm the first president ever I used to be a county official when I was 26 years old and always bothered me the federal government would send money to the state to be distributed to the county and what the hell the state going to send to the county for all state reps need the money but guess what under my administration to go straight to the county one of my best friends my name is Joe Bodnard from Scranton Pennsylvania Bobby Casey has been a great friend his dad was a great friend as well and by the way we grew up three blocks from one another three blocks and they still worry about it it's not showing up guess what I was on North Washington Avenue he was in Adams guess what they renamed North Washington Avenue down where I live Biden Way Bobby Bobby Bobby make sure we get reelected again and while we couldn't be here want to thank his partner in the Senate John Federman if you're in a foxhole you want Federman in there with you he couldn't be here today but guess what he sent the best part of the family just so she's here let me just say I mean so much to be with a true friend a true friend the vice president and the next great president of the United States of America I I come from two neighborhoods where it's not hard to say the word Union but you know what the fact of the matter is an awful lot of politicians have a trouble saying Union like they're working people guess what I'm not one of them in this common we know the simple truth Wall Street did not build America the middle class built America and unions built the middle class that's a fact by the way that is not a slogan that's a fact I asked the Treasury Department to do a study and it shows that when unions do well all workers in America do better that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that provides major incentives for companies to build new battery factories, wind turbines, and more to create high-paying jobs in those coal and natural gas communities and on top of that there's over four billion dollars in private companies who have committed to invest in clean energy and advanced manufacturing here in Pennsylvania four billion dollars in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States so folks, we got one more job to do together let me ask you, are you ready to fight? Yes! Are you ready to win? Yes! Are you ready to let Kamala Harris our next President of the United States in the United States? Yes! Applause And in the process are you ready to make Donald Trump a loser again? Yes! I've never been more optimistic about America because we have to remember who we are we're the United States of America there's nothing, nothing, I mean this in the bottom of my heart there's nothing beyond our capacity nothing when we do it together and that means, like my friend our great Vice President of the United States Kamala Harris Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Good afternoon Pittsburgh Applause Applause Thank you Joe Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause It is good to be in the House of Labor Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Now I don't have to tell the brothers and sisters of labor that you really get to know somebody when you're in the middle of a fight That's really great When times are hard When the forces are mighty When people don't believe something can get done and they have a thousand excuses for why it can't get done And I have spent more time with this extraordinary human being When the cameras were not in the room When the stakes were high When the heat was high When the heat was intense And Joe Biden has always stood with the workers of America and labor unions of America Always Always Applause Applause Applause I've been with him when he'll bring folks into the Oval Office and you know how Joe can get sometimes he doesn't spare words that sometimes the cameras are not in the room when he has those conversations Because the thing about the Joe Biden I know and I know you know because he has been a friend of labor for so long for his whole life Joe Biden can be quite impatient and that's a good thing for that kind of leader Quite impatient and I say to all of the friends here the press that's in the room history will show what we here know Joe Biden has been one of the most transformative presidents in the United States that we have ever witnessed Applause Applause Applause And it comes from his heart Applause Applause Applause Applause And you know Joe and I talk a lot about the fact that we are so proud to be the most pro-Union administration in America's history Applause Applause Applause Applause And as we know Joe still got a lot of work to do so let's also understand that So I want to thank all the incredible leaders who are here today including the Governor Shapiro Lieutenant Governor Davis Senator Casey who we will re-elect this November Mayor Gaining President Scholar President Cooper all the leaders of labor who are here all the Union members who are here so I'll just get right to a few points I love Labor Day I love celebrating Labor Day And Pittsburgh of course is a cradle of the American Labor movement It is the birthplace of the AFL headquarters of the steel workers home to firefighters local one and of course the historic IBEW Local 5 Applause Applause Applause For more than 150 years the brothers and sisters of labor have helped lead the fight for fair pay better benefits and safe working conditions and every person in our nation has benefited from that work you know everywhere I go I tell people you may not be a union member but you better thank unions for that 5 day work week Applause Thank unions for sick leave Thank unions for pay family leave Applause Thank unions for your vacation time Applause Applause Because when union wages go up everybody's wages go up when union workplaces are safer all workplaces are safer when unions are strong America is strong Applause Applause Applause Applause Applause Applause And we are clear not only has Pittsburgh shaped the history of America's labor movement today you are also shaping its future In 2021 with my dear friend the secretary Marty Walsh who the president appointed to be secretary of labor he and I hosted a meeting right here in this local and it was part of the White House Labor Task Force that I lead today we met with a group of computer programmers who were working to form a union one month later they signed their contract and became the first one of the first technology unions in our nation Applause Standing on the shoulder of all those who have been here and fought the good fight so Pittsburgh I remind us of that to say together we are fighting to build an economy that works for all working people Applause And that has always been the vision of the labor movement and that is the vision of our campaign you know in this election there are two very different visions for our nation one hours focused on the future the other focused on the past And the other focused on the future And the other focused on the future We fight for the future We fight for a future of dignity respect and opportunity for all people Applause Applause Applause We fight knowing it's some backward thinking for those folks who have been suggesting for years that the measure of the strength of a leader is based on who you beat down You know that's the stuff they're pushing That the measure of the strength of a leader is based on who you beat down when we know the true measure of the strength of a leader is based on who you lift up Applause Applause Who you lift up Applause Do you fight for workers? Do you fight for families? Do you fight for those who must be seen and heard and deserve the dignity that comes with hard work Applause That's what we fight for Applause And when you know what to stand for you know what to fight for Applause Applause So we're 64 days out from this election Laughter Laughter Ballots in Pennsylvania will start dropping in 14 days Applause 14 days Applause And this election is as much as anything else a fight for the promise of America Applause For the promise of America We love our country Applause And we know it is one of the highest forms of socialism to fight for the ideals of our country And that's what this election is about And about the promise of America And I don't need to tell unions what the promise looks like It's what you do every day Applause Applause Applause Applause But as we fight to move forward Donald Trump is trying to pull us backward Applause Including back to a time before workers had the freedom to organize Applause Well, the courts will handle that And we will handle November Applause Applause Applause We'll handle November, let the courts handle that Applause But we're not going back Applause Applause And one of the ways One of the ways we're going to guarantee we don't go back is that we remember Right? It is important to remember what that was and what it is Remember, as president Donald Trump blocked overtime benefits for millions of workers Applause He opposed efforts to raise the minimum wage Applause As the president said, he appointed union busters to the National Labor Relations Board Applause And don't forget, he supported so-called right to work laws Applause And if Donald Trump were to be re-elected he intends to give more tax cuts to billionaires and big corporations Applause He intends to cut Social Security and Medicare Applause He wants to impose what in effect would be a national sales tag I call it the Trump's national sales tag Applause On everyday products and basic necessities that would cost a typical American family the economist have said this Almost $4,000 a year Applause He intends to repeal the Affordable Care Act Applause And take us back to what we remember because it wasn't that long ago was a time when insurance companies could deny people pre-existing conditions Do you remember what that was? Children with asthma, breast cancer survivors grandparents with diabetes Applause Well look America has tried those failed policies before and we are not going back Applause Applause Applause We are not going back Applause We are not going back Applause And instead we fight for a future where no person has to go broke just because they get sick Applause And so building on the work of President Joe Biden and I and the work we have done in the White House we will continue to strengthen the Affordable Care Act and make prescription drugs affordable for all Americans Applause We We fight for a future where every worker has the freedom to organize and we will pass the Pro Act Applause And end union busting once and for all and Bob Casey will help us do that Applause Applause Applause Applause We see and know and fight for a future where every person has the opportunity not just to get by but to get ahead Applause And so we will continue to build what I call an opportunity economy so that every American has an opportunity to buy a home and start a business or build intergenerational wealth and have a future that matches their dreams and ambitions and aspirations Applause Because of course that's the nature of who we are as Americans We have dreams we can see what is possible unburdened by what has been We have aspirations We have ambitions and the system that is a good system is one that supports that and allows people the opportunity to go where they can see and imagine themselves to be That's what I'm talking about when I talk about an opportunity economy we fight for a future where every senior can retire with dignity and so we will continue to defend Social Security and Medicare And pensions And pensions And pensions Applause And we will continue to strengthen America's manufacturing sector and on that point the President mentioned it U.S. Steel is an historic American company and it is vital for our nation to maintain strong American Steel companies and I couldn't agree more with President Biden U.S. Steel should remain American owned and American operated Applause And I will always have the back of America's Steel workers Applause And all of America's workers Applause So friends 64 days until the most election of our lives and probably one of the most important in the life of our nation Truly And we know this is going to be a tight race to the very end It's going to be a tight race to the very end so let's not pay too much attention to those polls Because as unions and labor knows best we know what it's like to be the underdog And we are the underdog in this race And we have some hard work then ahead of us But here's the beauty of us in this room We like hard work Hard work is good work Hard work is joyful work Applause And so in this fight Applause I will continue to count on the strength, the determination and the hard work of the leaders in this room to knock on doors to get folks to the polls and bluntly put because the people in here do it to help us win Pennsylvania Applause So today I ask Are you ready to make your voices heard? Applause Do we believe in freedom? Applause Do we believe in opportunity? Applause Do we believe in the promise of America? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause\""
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"Joe Biden and Kamala Harris were walking our picket lines when Donald Trump was crossing them. Joe Biden and Kamala Harris have led the most pro-union White House in American history. And you remember that Kamala Harris cast those deciding votes in the Senate to save millions of workers' pensions and lower costs for seniors on their prescription drugs and make the biggest investment in modern history to rebuild this country. And now Kamala Harris and our union brother Tim Walz, yes, they are ready to go even further because they believe in that future that we all want to see. Now the road to the White House goes right through our union halls. That's right, one in five voters right here in Pennsylvania is a union voter. So we are the difference maker. We have the people. We have the trust. We know how to organize. And we are ready to send Kamala Harris and Tim Walz to the White House. Are we ready? All right, I got to hear you. Are you going to get your friends registered to vote? Yes. Are you going to knock on doors? Yes. Are you going to fight every day until November 5th? Yes. That's what I thought. Because when we fight, we fight. When we fight, we fight. Yes. Thank you. Now I have the great pleasure of introducing my friend, my brother, one of the great labor leaders in this country, IBEW International President, Kenny Cooper. Let's go, Cooper. Good afternoon, brothers and sisters. Good afternoon. Thank you, brothers and sisters. Thank you, guests. And most of all, thank you, family, for being here on Labor Day. You know, it's a great honor to be in Pittsburgh, a good union town, but for me, it's really an honor to be in the House of Labor. IBEW Local 5, thank you so much for everything you do. As Liz said, I'm the international president of the IBEW, the oldest and largest electrical union in the entire world. And on behalf of 840,000 members of the IBEW, it is my true honor to get to introduce tonight the strongest, most pro-union administration ever in history in the United States, President Biden and Vice President Harris. Joe Biden made a lot of promises when he run for president in 2022 or 2020. He promised to save Americans' pension system that was a serious risk for us. He promised to help American workers that were depending on him to help save that pension. Workers who went to work every day lived by the rules, who deferred their own wages so they could retire one day with dignity and respect. He passed the Butch Lewis Act, saving the American's multi-floor pension plan. And when the Senate was all tied up, let's think about this a minute, on the rescue of America's pension plans, they were only tied up for one reason. We couldn't find a Republican senator that would vote for American workers. Why would? The vice president and Harris showed us her real colors. She stepped to the plate, casted a deciding vote to save our pension plans across America. Showing working families that Biden and Harris administration has our backs, promises made, promises kept. He pledged to rebuild our country's infrastructure, the only way to make sense was good union jobs that pays well and has health care for them and their families. Once again, promises made, promises kept. They worked together to pass the Chips and Science Act, bringing back manufacturing jobs to communities that really need them the most. Promises made, promises kept. They pledged to be true friends of labor because they understand the necessity of unions to the American worker and to the middle class. Well, Joe Biden and Kamala Harris kept every single one of those promises. Pension plan relief, the Butch Lewis Act went above and beyond our expectations. His infrastructure bills are bringing good union jobs back, much needed infrastructure across our nation, in every corner of our nation. And he's never been afraid to say the word union. Joe Biden is more than just the pro union, the most pro union president in our entire history. When he passed the torch to Kamala Harris, he ensured his pro union, pro labor legacy would continue with the next administration. Kamala Harris understands just as Joe did and Joe does now. The only way to meet the future of this great nation is by giving workers a real voice at every table, especially the most important table to every worker and every worker's family, the kitchen table. Yeah. Brothers and sisters, please join me to welcome our true friends, the president and vice president of the United States, Joe Biden and Kamala Harris. Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Thank you, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe, Joe Yui, Yui went to the national president IW Abel and he said he wanted me he wanted me to get endorsed everybody thought it was crazy I literally wasn't old enough to be sworn in today I'd like to but guess what? I was unable to stuck with me they got stuck with me for the rest of my career Eric Dean the iron workers Tim Disco the bricklayer April Bowles the SEIU Lee Saunders the Rastman the great friend Jimmy Williams the painter's ally trade and his dad his dad is a really good man Mike Coleman the sheet metal worker also got some of the best elected officials America Governor Josh Shapiro is doing an incredible job the great lieutenant governor Austin Davis and one of America's best words Ed Ganey Ed you are doing a hell of a job and sir in the motto county executive I think is the hardest job in American politics everybody knows where you live and I think you can solve all the problems you don't have enough money well I tell you one thing I'm the first president ever I used to be a county official when I was 26 years old and always bothered me the federal government would send money to the state to be distributed to the county and what the hell the state going to send to the county for all state reps need the money but guess what under my administration to go straight to the county one of my best friends my name is Joe Bodnard from Scranton Pennsylvania Bobby Casey has been a great friend his dad was a great friend as well and by the way we grew up three blocks from one another three blocks and they still worry about it it's not showing up guess what I was on North Washington Avenue he was in Adams guess what they renamed North Washington Avenue down where I live Biden Way Bobby Bobby Bobby make sure we get reelected again and while we couldn't be here want to thank his partner in the Senate John Federman if you're in a foxhole you want Federman in there with you he couldn't be here today but guess what he sent the best part of the family just so she's here let me just say I mean so much to be with a true friend a true friend the vice president and the next great president of the United States of America I I come from two neighborhoods where it's not hard to say the word Union but you know what the fact of the matter is an awful lot of politicians have a trouble saying Union like they're working people guess what I'm not one of them in this common we know the simple truth Wall Street did not build America the middle class built America and unions built the middle class that's a fact by the way that is not a slogan that's a fact I asked the Treasury Department to do a study and it shows that when unions do well all workers in America do better that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that's a fact that provides major incentives for companies to build new battery factories, wind turbines, and more to create high-paying jobs in those coal and natural gas communities and on top of that there's over four billion dollars in private companies who have committed to invest in clean energy and advanced manufacturing here in Pennsylvania four billion dollars in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States in the United States so folks, we got one more job to do together let me ask you, are you ready to fight? Yes! Are you ready to win? Yes! Are you ready to let Kamala Harris our next President of the United States in the United States? Yes! Applause And in the process are you ready to make Donald Trump a loser again? Yes! I've never been more optimistic about America because we have to remember who we are we're the United States of America there's nothing, nothing, I mean this in the bottom of my heart there's nothing beyond our capacity nothing when we do it together and that means, like my friend our great Vice President of the United States Kamala Harris Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Good afternoon Pittsburgh Applause Applause Thank you Joe Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause It is good to be in the House of Labor Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Applause Now I don't have to tell the brothers and sisters of labor that you really get to know somebody when you're in the middle of a fight That's really great When times are hard When the forces are mighty When people don't believe something can get done and they have a thousand excuses for why it can't get done And I have spent more time with this extraordinary human being When the cameras were not in the room When the stakes were high When the heat was high When the heat was intense And Joe Biden has always stood with the workers of America and labor unions of America Always Always Applause Applause Applause I've been with him when he'll bring folks into the Oval Office and you know how Joe can get sometimes he doesn't spare words that sometimes the cameras are not in the room when he has those conversations Because the thing about the Joe Biden I know and I know you know because he has been a friend of labor for so long for his whole life Joe Biden can be quite impatient and that's a good thing for that kind of leader Quite impatient and I say to all of the friends here the press that's in the room history will show what we here know Joe Biden has been one of the most transformative presidents in the United States that we have ever witnessed Applause Applause Applause And it comes from his heart Applause Applause Applause Applause And you know Joe and I talk a lot about the fact that we are so proud to be the most pro-Union administration in America's history Applause Applause Applause Applause And as we know Joe still got a lot of work to do so let's also understand that So I want to thank all the incredible leaders who are here today including the Governor Shapiro Lieutenant Governor Davis Senator Casey who we will re-elect this November Mayor Gaining President Scholar President Cooper all the leaders of labor who are here all the Union members who are here so I'll just get right to a few points I love Labor Day I love celebrating Labor Day And Pittsburgh of course is a cradle of the American Labor movement It is the birthplace of the AFL headquarters of the steel workers home to firefighters local one and of course the historic IBEW Local 5 Applause Applause Applause For more than 150 years the brothers and sisters of labor have helped lead the fight for fair pay better benefits and safe working conditions and every person in our nation has benefited from that work you know everywhere I go I tell people you may not be a union member but you better thank unions for that 5 day work week Applause Thank unions for sick leave Thank unions for pay family leave Applause Thank unions for your vacation time Applause Applause Because when union wages go up everybody's wages go up when union workplaces are safer all workplaces are safer when unions are strong America is strong Applause Applause Applause Applause Applause Applause And we are clear not only has Pittsburgh shaped the history of America's labor movement today you are also shaping its future In 2021 with my dear friend the secretary Marty Walsh who the president appointed to be secretary of labor he and I hosted a meeting right here in this local and it was part of the White House Labor Task Force that I lead today we met with a group of computer programmers who were working to form a union one month later they signed their contract and became the first one of the first technology unions in our nation Applause Standing on the shoulder of all those who have been here and fought the good fight so Pittsburgh I remind us of that to say together we are fighting to build an economy that works for all working people Applause And that has always been the vision of the labor movement and that is the vision of our campaign you know in this election there are two very different visions for our nation one hours focused on the future the other focused on the past And the other focused on the future And the other focused on the future We fight for the future We fight for a future of dignity respect and opportunity for all people Applause Applause Applause We fight knowing it's some backward thinking for those folks who have been suggesting for years that the measure of the strength of a leader is based on who you beat down You know that's the stuff they're pushing That the measure of the strength of a leader is based on who you beat down when we know the true measure of the strength of a leader is based on who you lift up Applause Applause Who you lift up Applause Do you fight for workers? Do you fight for families? Do you fight for those who must be seen and heard and deserve the dignity that comes with hard work Applause That's what we fight for Applause And when you know what to stand for you know what to fight for Applause Applause So we're 64 days out from this election Laughter Laughter Ballots in Pennsylvania will start dropping in 14 days Applause 14 days Applause And this election is as much as anything else a fight for the promise of America Applause For the promise of America We love our country Applause And we know it is one of the highest forms of socialism to fight for the ideals of our country And that's what this election is about And about the promise of America And I don't need to tell unions what the promise looks like It's what you do every day Applause Applause Applause Applause But as we fight to move forward Donald Trump is trying to pull us backward Applause Including back to a time before workers had the freedom to organize Applause Well, the courts will handle that And we will handle November Applause Applause Applause We'll handle November, let the courts handle that Applause But we're not going back Applause Applause And one of the ways One of the ways we're going to guarantee we don't go back is that we remember Right? It is important to remember what that was and what it is Remember, as president Donald Trump blocked overtime benefits for millions of workers Applause He opposed efforts to raise the minimum wage Applause As the president said, he appointed union busters to the National Labor Relations Board Applause And don't forget, he supported so-called right to work laws Applause And if Donald Trump were to be re-elected he intends to give more tax cuts to billionaires and big corporations Applause He intends to cut Social Security and Medicare Applause He wants to impose what in effect would be a national sales tag I call it the Trump's national sales tag Applause On everyday products and basic necessities that would cost a typical American family the economist have said this Almost $4,000 a year Applause He intends to repeal the Affordable Care Act Applause And take us back to what we remember because it wasn't that long ago was a time when insurance companies could deny people pre-existing conditions Do you remember what that was? Children with asthma, breast cancer survivors grandparents with diabetes Applause Well look America has tried those failed policies before and we are not going back Applause Applause Applause We are not going back Applause We are not going back Applause And instead we fight for a future where no person has to go broke just because they get sick Applause And so building on the work of President Joe Biden and I and the work we have done in the White House we will continue to strengthen the Affordable Care Act and make prescription drugs affordable for all Americans Applause We We fight for a future where every worker has the freedom to organize and we will pass the Pro Act Applause And end union busting once and for all and Bob Casey will help us do that Applause Applause Applause Applause We see and know and fight for a future where every person has the opportunity not just to get by but to get ahead Applause And so we will continue to build what I call an opportunity economy so that every American has an opportunity to buy a home and start a business or build intergenerational wealth and have a future that matches their dreams and ambitions and aspirations Applause Because of course that's the nature of who we are as Americans We have dreams we can see what is possible unburdened by what has been We have aspirations We have ambitions and the system that is a good system is one that supports that and allows people the opportunity to go where they can see and imagine themselves to be That's what I'm talking about when I talk about an opportunity economy we fight for a future where every senior can retire with dignity and so we will continue to defend Social Security and Medicare And pensions And pensions And pensions Applause And we will continue to strengthen America's manufacturing sector and on that point the President mentioned it U.S. Steel is an historic American company and it is vital for our nation to maintain strong American Steel companies and I couldn't agree more with President Biden U.S. Steel should remain American owned and American operated Applause And I will always have the back of America's Steel workers Applause And all of America's workers Applause So friends 64 days until the most election of our lives and probably one of the most important in the life of our nation Truly And we know this is going to be a tight race to the very end It's going to be a tight race to the very end so let's not pay too much attention to those polls Because as unions and labor knows best we know what it's like to be the underdog And we are the underdog in this race And we have some hard work then ahead of us But here's the beauty of us in this room We like hard work Hard work is good work Hard work is joyful work Applause And so in this fight Applause I will continue to count on the strength, the determination and the hard work of the leaders in this room to knock on doors to get folks to the polls and bluntly put because the people in here do it to help us win Pennsylvania Applause So today I ask Are you ready to make your voices heard? Applause Do we believe in freedom? Applause Do we believe in opportunity? Applause Do we believe in the promise of America? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause Are you ready to make your voice heard? Applause\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function Testing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a7MUjNpm8Ry"
      },
      "source": [
        "## Single link test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDHZnrYEk64P",
        "outputId": "a9fc129b-ae58-498c-aa02-b22b9c3ba786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=6G1Oou2dVdk&ab_channel=WFAA\n",
            "[youtube] 6G1Oou2dVdk: Downloading webpage\n",
            "[youtube] 6G1Oou2dVdk: Downloading tv client config\n",
            "[youtube] 6G1Oou2dVdk: Downloading player 236fc64d-main\n",
            "[youtube] 6G1Oou2dVdk: Downloading tv player API JSON\n",
            "[youtube] 6G1Oou2dVdk: Downloading ios player API JSON\n",
            "[youtube] 6G1Oou2dVdk: Downloading m3u8 information\n",
            "[info] 6G1Oou2dVdk: Downloading 1 format(s): 251\n",
            "[download] Destination: audio\n",
            "[download] 100% of   23.40MiB in 00:00:09 at 2.43MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:19<00:00, 24.9MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 183042/189042 [01:52<00:03, 1625.43frames/s]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "youtube_url = \"https://www.youtube.com/watch?v=6G1Oou2dVdk&ab_channel=WFAA\"\n",
        "start_time = 58  # Start time in seconds\n",
        "duration = 60     # Optional: Duration to transcribe in seconds\n",
        "\n",
        "#process\n",
        "download_audio(youtube_url, start_time)\n",
        "test,row = new_transcribe_audio(start_time)\n",
        "out = clean_transcript(test['full_text'])\n",
        "\n",
        "# Clean up\n",
        "os.remove(\"audio.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6-c9l4VLlCAe",
        "outputId": "2c83b02e-fce8-4610-a3f2-c76f66a7cfbd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" Good evening, everyone. Good evening. And thank you for taking the time out of your  busy lives. Thank you. Thank you. Thank you. Thank you, everyone. So listen, one week from  today, you will have the chance to make a decision that directly impacts your life, the life  of your family, and the future of this country we love. And it will probably be the most  important vote you ever cast. And this election is more than just a choice between two parties  and two different candidates. It is a choice about whether we have a country rooted in  freedom for every American or ruled by chaos and division. Many of you watching have probably  already cast your ballots. But I know many others are still considering who to vote for  or whether you'll vote at all. So tonight, I will speak to everyone about the choice  and the stakes in this election. Look, we know who Donald Trump is. He is the person who stood  at this very spot nearly four years ago and sent an armed mob to the United States Capitol  to overturn the will of the people in a free and fair election. An election that he knew  he lost. Americans died as a result of that attack. 140 law enforcement officers were  injured because of that attack. And while Donald Trump sat in the White House watching  as the violence unfolded on television, he was told by his staff that the mob wanted to  kill his own vice president. And Donald Trump responded with two words. So what? America,  that's who Donald Trump is. And that's who is asking you to give him another four years  in the Oval Office. Not to focus on your problems, but to focus on his. And Donald Trump has  told us his priorities for a second term. He has an enemy's list of people he intends to  prosecute. He says that one of his highest priorities is to set free the violent extremists  who insulted those law enforcement officers on January 6th. Donald Trump intends to use  the United States military against American citizens who simply disagree with him. People,  he calls quote, the enemy from within. America, this is not a candidate for president who  is thinking about how to make your life better. This is someone who is unstable, obsessed with  revenge, consumed with grievance, and out for unchecked power. Donald Trump has spent a decade  trying to keep the American people divided and afraid of each other. That is who he is.  But America, I am here tonight to say that is not who we are. That is not who we are.  You see, what Donald Trump has never understood is that e pluribus unum out of many one isn't  just a phrase on a dollar bill. It is a living truth about the heart of our nation, our democracy,  doesn't require us to agree on everything. In fact, we like good arguments from time to time. Just  think of your own family, right? It is not the American way to not have disagreements. We don't  shy away from robust debate. We like a good debate, don't we? We like a good debate. And the fact  that someone disagrees with us does not make them the enemy within. They are family, neighbors,  classmates, coworkers. They are fellow Americans. And as Americans, we rise and fall together.  America, for too long we have been consumed with too much division, chaos, and mutual  distrust. And it can be easy then to forget a simple truth. It doesn't have to be this  way. It doesn't have to be this way. It is time to stop pointing fingers. We have to stop  pointing fingers and start locking arms. It is time to turn the page on the drama and the  conflict, the fear, and division. It is time for a new generation of leadership in America.  And I am ready to offer that leadership as the next President of the United States of America.  Now look, let me say, let me say, I recognize this has not been a typical campaign. Even  though I have had the honor of serving as your Vice President for the last four years, I know,  but I know that many of you are still getting to know who I am. Well, let me tell you, I am  someone who has spent most of my career outside of Washington, D.C. So I know that not all the good  ideas come from here. I am not afraid of tough fights against bad actors and powerful interests.  Because for decades, as a prosecutor and a top law enforcement officer of our biggest state, I won  fights against big banks that ripped off homeowners, against for-profit colleges that scammed veterans  and students, against predators who abused women and children, and cartels that trafficked in guns,  drugs, and human beings. And I did this work because for as long as I can remember, I have  always had an instinct to protect. There's something about people being treated unfairly or overlooked  that frankly just gets to me. I don't like it. It's what my mother instilled in me. A drive to hold  accountable those who use their wealth or power to take advantage of other people. The drive to protect  hard-working Americans who aren't always seen or heard and deserve a voice. And I will tell you that is the kind  of president I will be. And look, I'll be honest with you, I'm not perfect. I make mistakes. But here's what  I promise you. I will always listen to you. Even if you don't vote for me, I will always tell you the truth.  Even if it is difficult to hear, I will work every day to build consensus and reach compromise to get things done.  And if you give me the chance to fight on your behalf, there is nothing in the world that will stand in my way.  So look, in less than 90 days, either Donald Trump or I will be in the Oval Office.  On day one, on day one, and on day one, if elected, on day one if elected, Donald Trump would walk into that office  with an enemy's list. When elected, I will walk in with a to-do list full of priorities of what I will get done for the American people.  And I will work with everyone, Democrats, Republicans, and Independents, to help Americans who are working hard and still struggling to get ahead.  I have been honored to serve as Joe Biden's Vice President. But I will bring my own experiences and ideas to the Oval Office.  My presidency will be different because the challenges we face are different. Our top priority as a nation four years ago was to end the pandemic and rescue the economy.  Now, our biggest challenge is to lower costs, costs that were rising even before the pandemic, and that are still too high. I get it.  I still remember our mother sitting at that yellow Formica table late at night, cup of tea in hand, a pile of bills in front of her, trying to make it all work.  And I've heard from so many of you who are facing even greater financial pressures. Donald Trump's answer to you is the same as it was the last time.  Another trillion dollars in tax cuts for billionaires and big corporations. And this time, he will pay for it with a 20% national sales tax on everything you buy that is imported.  Think about it. Clothes, food, toys, cell phones, a Trump sales tax that would cost the average family nearly $4,000 more a year.  And on top of that, you will pay even more if Donald Trump finally gets his way and repeals the Affordable Care Act.  Which would throw millions of Americans off their health insurance and take us back to when insurance companies had the power to deny people with preexisting conditions.  Well, we are not going back. We are not going back.  We are not going back.  We are not going back. Because we also know Donald Trump would deliver tax cuts to his billionaire donors. I will deliver tax cuts to working people and the middle class.  I will make sure you have a chance not just to get by but to get ahead. Because I believe in honoring the dignity of work.  I will enact the first ever federal ban on price gouging on groceries.  Cap the price of insulin and limit out-of-pocket prescription costs for all Americans.  I will fight to make sure that hardworking Americans can actually afford a place to live.  I will never forget how our mother saved up and how excited she was when she could finally afford to buy our first home.  I remember how excited she was. And I know that owning a home is not only a measure of financial security. It is about the pride of your hard work.  As president, I will fight to help first-time home buyers with your down payment, take on the companies that are jacking up rents and build millions of new homes.  There's, we have heard excuses about why America can't build enough housing. Enough with the excuses, I'm going to cut the red tape and work with the private sector and local governments to speed up building and get it done.  And the cost of housing isn't the only financial pressure on middle-class families. I have met so many young people who have a natural desire to parent their children well, but not always the resources to do it.  So I'll fight for a child tax credit to save them some money, which will also lift American children out of poverty.  Our work to lower the cost of childcare, which is out of reach for too many working families today, and for too many people in the sandwich generation who are raising young children and taking care of a parent, juggling all of it is extremely difficult.  You know, I took care of my mother when she got sick, cooking foods that she had a taste for, finding clothes that would not irritate her skin, and understand, as I do, that caregiving is about dignity. It is about dignity.  And currently, if you need home care and you don't have some money to hire someone, you and your family need to deplete your savings to qualify for help. That's just not right.  So we're going to change the approach and allow Medicare to cover the cost of home care so seniors can get the help and care they need in their own homes.  Now, Donald Trump has a different approach. He tried to cut Medicare and Social Security every year he was president.  Look, I believe that when people have worked hard their entire life, they deserve to retire with the benefits they have earned.  And I believe in the fundamental freedom of Americans to make decisions about their own bodies and not have their government tell them what to do.  I will fight to restore what Donald Trump and his hand selected Supreme Court justices took away from the women of America.  That today, one in three women in America, think about it, one in three women in America lives in a state with a Trump abortion ban, many with no exceptions even for rape and incest.  The idea that a woman who survives a crime of a violation to her body should not have the authority to make a decision about what happens to her body next, that is immoral.  And Trump's not done. He would ban abortion nationwide, restrict access to birth control and put IVF treatments at risk, and force states to monitor women's pregnancies.  Just Google Project 2025 and read the plans for yourself.  And look, I think we all know one does not have to abandon their faith or deeply held beliefs to simply agree the government should not be telling her what to do with her body.  Not the government.  And when Congress passes a bill to restore reproductive freedom nationwide as President of the United States, I will proudly sign it into law.  Proudly.  And look, on another subject, politicians have got to stop treating immigration as an issue to scare up votes in an election.  And instead treat it as the serious challenge that it is that we must finally come together to solve.  I will work with Democrats and Republicans to sign into law the border security bill that Donald Trump killed.  When I was Attorney General of a border state, I saw the chaos and violence caused by transnational criminal organizations that I took on.  And when I am President, we will quickly remove those who arrive here unlawfully, prosecute the cartels, and give Border Patrol the support they so desperately need.  At the same time, we must acknowledge we are a nation of immigrants.  And I will work with Congress to pass immigration reform, including an earned path to citizenship for hardworking immigrants like farm workers and our dreamers.  As Commander-in-Chief, I will make sure America has the strongest, most lethal fighting force in the world.  Donald Trump, on the other hand, has shown his contempt for our nation's heroes, calls them suckers and losers, called a four-star Marine General a quote, low life.  I will always honor, never denigrate, the service and sacrifice of our troops and their families, and fulfill our sacred obligation to care for them.  I will strengthen, not surrender, America's global leadership.  And I will stand with our friends because I know that our alliances keep American people safe and make America stronger and more secure.  Look, world leaders think that Donald Trump is an easy mark, easy to manipulate with flattery or favor.  And you can believe that autocrats like Putin and Kim Jong-un are rooting for him in this election.  I will always uphold our security, advance our national interests, and ensure that the United States of America remains as we must forever be a champion of liberty around the world.  America, we know what Donald Trump has in mind.  More chaos, more division, and policies that help those at the very top and hurt everyone else.  I offer a different path, and I ask for your vote.  And here is my pledge to you.  I pledge to seek common ground and common sense solutions to make your life better.  I am not looking to score political points.  I am looking to make progress.  I pledge to listen, to experts, to those who will be impacted by the decisions I make, and to people who disagree with me.  Unlike Donald Trump, I don't believe people who disagree with me are the enemy.  He wants to put them in jail.  I'll give them a seat at the table.  I pledge to you to approach my work with the joy and optimism that comes from making a difference in people's lives.  And I pledge to be a president for all Americans.  And to always put country above party and self.  I love our country with all my heart.  And I believe in its promise because I've lived it.  I grew up as a child of the Civil Rights Movement.  My parents would take me to marches in a stroller where crowds of people of all races,  faiths, and walks of life came together to fight for the ideals of freedom and opportunity.  I've lived the promise of America.  I saw how hard our mother worked to give her daughters the same chances this country gave her.  Growing up, I was blessed to have family by blood and family by love,  who instilled in me the values of community, compassion, and faith that have always defined our nation at its best.  I've lived the promise of America.  I've spent my life fighting for the people who have been hurt and counted out,  but never stopped believing that in our country anything is possible.  I've lived the promise of America.  And I see the promise of America in all of you.  In all of you.  I see it.  I see it in the young people who are voting for the first time,  who are determined to live free from gun violence and to protect our planet and to shape the world they inherit.  I see it in the women who refuse to accept a future without reproductive freedom.  And the men who support them.  I see it in Republicans who have never voted for a Democrat before,  but have put the Constitution of the United States over party.  I've seen it in Americans different in many respects,  but united in our pursuit of freedom,  our belief in fairness and decency,  and our faith in a better future.  America, I know the vast majority of us have so much more in common than what separates us.  I know it.  And that's why I am in this race, to fight for the people just like I always have.  Yeah.  Nearly 250 years ago, America was born when we rested freedom from a petty tyrant.  Across the generations, Americans have preserved that freedom,  expanded it, and in so doing, proved to the world  that a government of, by, and for the people is strong and can endure.  And those who came before us, the patriots at Normandy and Selma,  Seneca Falls and Stonewall, on farmlands and factory floors,  they did not struggle, sacrifice, and lay down their lives  only to see us cede our fundamental freedoms.  They didn't do that, only to see us submit to the will of another petty tyrant.  These United States of America, we are not a vessel for the schemes of wannabe dictators.  The United States of America is the greatest idea humanity ever devised.  A nation big enough to encompass all our dreams, strong enough to withstand any fracture or fissure between us,  and fearless enough to imagine a future of possibilities.  So America, let us reach for that future.  Let us fight for this beautiful country we love.  And in seven days, we have the power, each of you has the power to turn the page  and start writing the next chapter in the most extraordinary story ever told.  I thank you all. God bless you and may God bless the United States of America. Thank you.  Thank you.  Thank you.\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VlAbENJrFm9"
      },
      "source": [
        "## Chunking full text\n",
        "\n",
        "\n",
        "https://www.restack.io/p/text-chunking-answer-python-file-chunking-cat-ai\n",
        "\n",
        "https://www.pinecone.io/learn/chunking-strategies/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlGf1hJwv9kh",
        "outputId": "228ec773-d25f-48b7-df6d-efd128bf04d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.4.1\n",
            "    Uninstalling sentence-transformers-3.4.1:\n",
            "      Successfully uninstalled sentence-transformers-3.4.1\n",
            "Successfully installed sentence-transformers-4.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaBoS2-5uLs4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "500-1000 words\n",
        "\n",
        "keep rhetorical info within chunk:\n",
        "  -use transition markers\n",
        "'''\n",
        "\n",
        "chunks = semantic_chunk_for_pentad(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIu8RhLwtnDQ"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "def semantic_chunk_for_pentad(speech_text, threshold=0.65, min_chunk_size=3, max_chunk_size=15):\n",
        "    \"\"\"\n",
        "    Create semantic chunks from campaign speech text for pentad analysis.\n",
        "\n",
        "    Args:\n",
        "        speech_text (str): Full campaign speech text\n",
        "        threshold (float): Cosine similarity threshold (0-1)\n",
        "        min_chunk_size (int): Minimum sentences per chunk\n",
        "        max_chunk_size (int): Maximum sentences per chunk\n",
        "\n",
        "    Returns:\n",
        "        list: List of semantically coherent text chunks\n",
        "    \"\"\"\n",
        "    # Simple sentence splitting without NLTK\n",
        "    # Split on periods followed by whitespace or end of string\n",
        "    sentences = [s.strip() for s in speech_text.replace('\\n', ' ').split('. ')]\n",
        "    sentences = [s + '.' if not s.endswith('.') else s for s in sentences if s]\n",
        "\n",
        "    # Load model for embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Generate embeddings for all sentences\n",
        "    embeddings = model.encode(sentences)\n",
        "\n",
        "    # Initialize variables\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_chunk_embeddings = []\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        if not current_chunk:\n",
        "            # Start a new chunk\n",
        "            current_chunk.append(sentence)\n",
        "            current_chunk_embeddings.append(embeddings[i])\n",
        "        else:\n",
        "            # Calculate similarity with the average of current chunk\n",
        "            avg_embedding = np.mean(current_chunk_embeddings, axis=0)\n",
        "            similarity = util.pytorch_cos_sim(embeddings[i], avg_embedding).item()\n",
        "\n",
        "            # Check if sentence is similar enough to current chunk\n",
        "            if similarity >= threshold and len(current_chunk) < max_chunk_size:\n",
        "                current_chunk.append(sentence)\n",
        "                current_chunk_embeddings.append(embeddings[i])\n",
        "            else:\n",
        "                # Check if current chunk is large enough\n",
        "                if len(current_chunk) >= min_chunk_size:\n",
        "                    chunks.append(' '.join(current_chunk))\n",
        "                    current_chunk = [sentence]\n",
        "                    current_chunk_embeddings = [embeddings[i]]\n",
        "                else:\n",
        "                    # If chunk is too small, continue adding to it despite lower similarity\n",
        "                    current_chunk.append(sentence)\n",
        "                    current_chunk_embeddings.append(embeddings[i])\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2NCn22d_wrEN",
        "outputId": "6add8fe0-cd65-42d1-81aa-0a3dae2ff852"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Thank you, everyone. So listen, one week from today, you will have the chance to make a decision that directly impacts your life, the life of your family, and the future of this country we love. And it will probably be the most important vote you ever cast.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "q1rMM-vtx1Qp",
        "outputId": "4d4d37d8-2d5e-40b1-86ed-3a9be367a2d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'And this election is more than just a choice between two parties and two different candidates. It is a choice about whether we have a country rooted in freedom for every American or ruled by chaos and division. Many of you watching have probably already cast your ballots.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "PYESEHxsyDI3",
        "outputId": "8b17b258-805a-4f41-f315-eda6ce7d3084"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"But I know many others are still considering who to vote for or whether you'll vote at all. So tonight, I will speak to everyone about the choice and the stakes in this election. Look, we know who Donald Trump is.\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBB3Wl9jyof8"
      },
      "source": [
        "### larger chunking test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ORV9pAJyOLM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_chunker (speech_text, threshold=0.6, min_sentences=5, target_chunk_size=2000, max_chunk_size=4000):\n",
        "    \"\"\"\n",
        "    Create semantic chunks from campaign speech text for pentad analysis,\n",
        "    optimized for LLM processing with larger chunk sizes.\n",
        "\n",
        "    Args:\n",
        "        speech_text (str): Full campaign speech text\n",
        "        threshold (float): Cosine similarity threshold (0-1)\n",
        "        min_sentences (int): Minimum sentences before considering a chunk complete\n",
        "        target_chunk_size (int): Target character size for chunks (optimal for LLM)\n",
        "        max_chunk_size (int): Maximum character size for chunks (LLM constraint)\n",
        "\n",
        "    Returns:\n",
        "        list: List of semantically coherent text chunks\n",
        "    \"\"\"\n",
        "    # Simple sentence splitting\n",
        "    sentences = [s.strip() for s in speech_text.replace('\\n', ' ').split('. ')]\n",
        "    sentences = [s + '.' if not s.endswith('.') else s for s in sentences if s]\n",
        "\n",
        "    # Load model for embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Generate embeddings for all sentences\n",
        "    embeddings = model.encode(sentences)\n",
        "\n",
        "    # Initialize variables\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_chunk_embeddings = []\n",
        "    current_chunk_chars = 0\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        sentence_chars = len(sentence)\n",
        "\n",
        "        if not current_chunk:\n",
        "            # Start a new chunk\n",
        "            current_chunk.append(sentence)\n",
        "            current_chunk_embeddings.append(embeddings[i])\n",
        "            current_chunk_chars += sentence_chars\n",
        "        else:\n",
        "            # Calculate similarity with the average of current chunk\n",
        "            avg_embedding = np.mean(current_chunk_embeddings, axis=0)\n",
        "            similarity = util.pytorch_cos_sim(embeddings[i], avg_embedding).item()\n",
        "\n",
        "            # Logic for adding sentences to chunks based on multiple criteria:\n",
        "            # 1. If very similar and below max size - add to current chunk\n",
        "            # 2. If reached target size with enough sentences - start new chunk\n",
        "            # 3. If would exceed max size - force start new chunk\n",
        "\n",
        "            if (similarity >= threshold and\n",
        "                current_chunk_chars + sentence_chars <= max_chunk_size):\n",
        "                # Add to current chunk if similar enough and within size limits\n",
        "                current_chunk.append(sentence)\n",
        "                current_chunk_embeddings.append(embeddings[i])\n",
        "                current_chunk_chars += sentence_chars\n",
        "            elif (len(current_chunk) >= min_sentences and\n",
        "                  current_chunk_chars >= target_chunk_size):\n",
        "                # Start new chunk if current chunk is big enough\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                current_chunk = [sentence]\n",
        "                current_chunk_embeddings = [embeddings[i]]\n",
        "                current_chunk_chars = sentence_chars\n",
        "            elif current_chunk_chars + sentence_chars > max_chunk_size:\n",
        "                # Force start new chunk if would exceed max size\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                current_chunk = [sentence]\n",
        "                current_chunk_embeddings = [embeddings[i]]\n",
        "                current_chunk_chars = sentence_chars\n",
        "            else:\n",
        "                # Add to current chunk even if less similar\n",
        "                current_chunk.append(sentence)\n",
        "                current_chunk_embeddings.append(embeddings[i])\n",
        "                current_chunk_chars += sentence_chars\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    # Post-processing: Combine consecutive chunks if they're small\n",
        "    i = 0\n",
        "    while i < len(chunks) - 1:\n",
        "        combined_size = len(chunks[i]) + len(chunks[i+1]) + 1  # +1 for space\n",
        "        if combined_size <= target_chunk_size:\n",
        "            chunks[i] = chunks[i] + ' ' + chunks[i+1]\n",
        "            chunks.pop(i+1)\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPkarJL7yuWG"
      },
      "outputs": [],
      "source": [
        "test = test_chunker(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "d0A3Xh2kyw3n",
        "outputId": "7fafd1b9-b313-42b0-a25e-9684aae931c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Good evening, everyone. Good evening. And thank you for taking the time out of your busy lives. Thank you. Thank you. Thank you. Thank you, everyone. So listen, one week from today, you will have the chance to make a decision that directly impacts your life, the life of your family, and the future of this country we love. And it will probably be the most important vote you ever cast. And this election is more than just a choice between two parties and two different candidates. It is a choice about whether we have a country rooted in freedom for every American or ruled by chaos and division. Many of you watching have probably already cast your ballots. But I know many others are still considering who to vote for or whether you'll vote at all. So tonight, I will speak to everyone about the choice and the stakes in this election. Look, we know who Donald Trump is. He is the person who stood at this very spot nearly four years ago and sent an armed mob to the United States Capitol to overturn the will of the people in a free and fair election. An election that he knew he lost. Americans died as a result of that attack. 140 law enforcement officers were injured because of that attack. And while Donald Trump sat in the White House watching as the violence unfolded on television, he was told by his staff that the mob wanted to kill his own vice president. And Donald Trump responded with two words. So what? America, that's who Donald Trump is. And that's who is asking you to give him another four years in the Oval Office. Not to focus on your problems, but to focus on his. And Donald Trump has told us his priorities for a second term. He has an enemy's list of people he intends to prosecute. He says that one of his highest priorities is to set free the violent extremists who insulted those law enforcement officers on January 6th. Donald Trump intends to use the United States military against American citizens who simply disagree with him. People, he calls quote, the enemy from within. America, this is not a candidate for president who is thinking about how to make your life better.\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "n08EgEaJyyem",
        "outputId": "01f90512-5f11-4b73-b824-1775699b07ef"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"This is someone who is unstable, obsessed with revenge, consumed with grievance, and out for unchecked power. Donald Trump has spent a decade trying to keep the American people divided and afraid of each other. That is who he is. But America, I am here tonight to say that is not who we are. That is not who we are. You see, what Donald Trump has never understood is that e pluribus unum out of many one isn't just a phrase on a dollar bill. It is a living truth about the heart of our nation, our democracy, doesn't require us to agree on everything. In fact, we like good arguments from time to time. Just think of your own family, right? It is not the American way to not have disagreements. We don't shy away from robust debate. We like a good debate, don't we? We like a good debate. And the fact that someone disagrees with us does not make them the enemy within. They are family, neighbors, classmates, coworkers. They are fellow Americans. And as Americans, we rise and fall together. America, for too long we have been consumed with too much division, chaos, and mutual distrust. And it can be easy then to forget a simple truth. It doesn't have to be this way. It doesn't have to be this way. It is time to stop pointing fingers. We have to stop pointing fingers and start locking arms. It is time to turn the page on the drama and the conflict, the fear, and division. It is time for a new generation of leadership in America. And I am ready to offer that leadership as the next President of the United States of America. Now look, let me say, let me say, I recognize this has not been a typical campaign. Even though I have had the honor of serving as your Vice President for the last four years, I know, but I know that many of you are still getting to know who I am. Well, let me tell you, I am someone who has spent most of my career outside of Washington, D.C. So I know that not all the good ideas come from here. I am not afraid of tough fights against bad actors and powerful interests. Because for decades, as a prosecutor and a top law enforcement officer of our biggest state, I won fights against big banks that ripped off homeowners, against for-profit colleges that scammed veterans and students, against predators who abused women and children, and cartels that trafficked in guns, drugs, and human beings.\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnJ1b7Zby9yn",
        "outputId": "0220d2cf-ea3f-4e95-ccde-4cca04e28946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2332"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJQEBQ8ezAyC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sentence_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00140994568049dd801a8dfb4333bebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00c5634db1fb409ea3f1f5985f133692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ef744095724f2787f080f99fe7c137",
            "placeholder": "​",
            "style": "IPY_MODEL_128b870d01fc46939742e7294e2c518b",
            "value": "vocab.txt: 100%"
          }
        },
        "01e96b8fc9344e16935ac7d164cbb932": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c5f9d942324f89a8048060f8d4ef9f",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b79e22a66641efbbfe799f22d0431c",
            "value": " 116/116 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "061993bae7fd48c1a70e1b4e16974065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_534180673f644d21a2fd4e7f7d9cced9",
              "IPY_MODEL_a47848ac8ee343e58d65552503a6121a",
              "IPY_MODEL_01e96b8fc9344e16935ac7d164cbb932"
            ],
            "layout": "IPY_MODEL_c04c70b97fd14050a6931f4582a5dab0"
          }
        },
        "074aca510bba49609b8ee88b2fcfe271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0978e75e7d7140e8b5460dee56f18562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a495f19511049168893230f4ebdeceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31ccb03636994e2d8f90dc9f21d24288",
              "IPY_MODEL_49d1bf1f43c04291995858cd501edcc8",
              "IPY_MODEL_dd773cdea9ac4927975f0b9279a08878"
            ],
            "layout": "IPY_MODEL_f0fd25ed81cd43989b46b29e33aac2c1"
          }
        },
        "0a5cf28baf1640c7a6e0c35fbb6a6bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b32cae4eb3a4f55a649b9e75683bbdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf21065e7f04f6ea393e7205ab1856b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128b870d01fc46939742e7294e2c518b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13fbf4013cf14b18a563610f6eb755cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14729e1b330d4fb297261b42cac635c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16fbf1be801b4e7cb566cc9058ca2cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a9625ca92d84fadb111b4ca64408582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab5f9cd5dde4b228158589c0964c537": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0103bbe17f43c4992903558ef0eacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b52bef3b092d4d328ed17b7fd98c947e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae7df6d4e33442f7b406cead0f3e1d32",
            "value": 112
          }
        },
        "1d3e98bb1c08496c807c584d65fec5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f58584d6c720411882e46f327f7c7f0f",
              "IPY_MODEL_b9817529ffc74e74a0a1e553bdb02f3a",
              "IPY_MODEL_3d45f216a7004d0c8137e22a9cd9e93a"
            ],
            "layout": "IPY_MODEL_13fbf4013cf14b18a563610f6eb755cb"
          }
        },
        "2a6fd1e42dfd4a988191b1aa17f39481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eae978a37d5456fba401c3ac2cfd281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b32cae4eb3a4f55a649b9e75683bbdc",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0978e75e7d7140e8b5460dee56f18562",
            "value": 349
          }
        },
        "31ccb03636994e2d8f90dc9f21d24288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6547ab549371435aaf3f7fc82e80e055",
            "placeholder": "​",
            "style": "IPY_MODEL_074aca510bba49609b8ee88b2fcfe271",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "31cfaf4abd9c4bd78bceadcbdf03ce52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31e66d0502ef454a9ba5b815a15c487e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "325261339dbb4c3baae75c0243b97894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32e2383eaa954d849be8887c7c0e2dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34ed50d452de4c33bb5621930e2932c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379fee9b3fa442a8b4a3d3df72cd6ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38167e3d416e4863aaa69fb0936c17d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a9625ca92d84fadb111b4ca64408582",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac9735d6d16401e9e58042cf415186a",
            "value": " 612/612 [00:00&lt;00:00, 54.9kB/s]"
          }
        },
        "385b0d651cb14e4bb3b691839dd86e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d1986f699004f8f8c62a761f1e2a2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa651f5104cf48c08be78bdfb7ea62b5",
              "IPY_MODEL_6b972c7773f9422eb4d4323fc3dcb244",
              "IPY_MODEL_bfbc80a22b804c5f8b500291651c13e8"
            ],
            "layout": "IPY_MODEL_31e66d0502ef454a9ba5b815a15c487e"
          }
        },
        "3d45f216a7004d0c8137e22a9cd9e93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fdb6e25c778426c8f65754c79f2835a",
            "placeholder": "​",
            "style": "IPY_MODEL_783ec1a0a7c14e1e99d3b31d6d83a63a",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.14MB/s]"
          }
        },
        "4098339497fe411d9465c174831c308d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c5f9d942324f89a8048060f8d4ef9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e4166108d9463691f64b19d0958f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471a965f07ce4c108fe86d40141a7a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49d1bf1f43c04291995858cd501edcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac02ab11bc8e45c7939d461ba997459d",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_385b0d651cb14e4bb3b691839dd86e57",
            "value": 350
          }
        },
        "4e9d93e62e8245c3989abef76ae7016b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b4c421f0874d4b85b9d6cb9290230d",
            "placeholder": "​",
            "style": "IPY_MODEL_a7fc79ab819d444984b2e59a3d261eb5",
            "value": " 466k/466k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "4f22c20678d04521826145ab8e06e997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51afd5a3515147109548b5363af07048": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534180673f644d21a2fd4e7f7d9cced9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf21065e7f04f6ea393e7205ab1856b",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d39e6b3b764f79869ccb4ecfc717a6",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "5345d5224df44d3c891dedef1a8a2db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55ba4a2aa8d645f99ee0443b46961e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60eeee1a20ed478d91b1f5a9e419a4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e0f3c375934d549fa21a9d509d3689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6522256761bc4f1c80c0635a08b2092a",
              "IPY_MODEL_1d0103bbe17f43c4992903558ef0eacb",
              "IPY_MODEL_f694a0297f3b49688d8c498632f26ba4"
            ],
            "layout": "IPY_MODEL_ea543f542f224aeab710cf938d019879"
          }
        },
        "6522256761bc4f1c80c0635a08b2092a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c184fdae342444f3a42859c74194e07d",
            "placeholder": "​",
            "style": "IPY_MODEL_4f22c20678d04521826145ab8e06e997",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6547ab549371435aaf3f7fc82e80e055": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680378ca40984e879894417bf11a5ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5cf28baf1640c7a6e0c35fbb6a6bef",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32e2383eaa954d849be8887c7c0e2dab",
            "value": 90868376
          }
        },
        "6833a96856cb41e1bd2d2852a63914b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c426dfbe964241a78dcf40f696ad5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b972c7773f9422eb4d4323fc3dcb244": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88cf91f9224425e88110e6e2dc011f1",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14729e1b330d4fb297261b42cac635c5",
            "value": 53
          }
        },
        "70689a912f7c4359b9c245dc3d868d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783ec1a0a7c14e1e99d3b31d6d83a63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ca9aefd92c944b9a120f06ea334b675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d4b2787b26e4f0d9bdc5acd3ed4779e",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa3e622aae52401d8b00174e682fcd87",
            "value": 612
          }
        },
        "7d4b2787b26e4f0d9bdc5acd3ed4779e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80642c18a20f400f82977005f4718a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80cbf90171e0462ba2b35907b4e2c955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868b4b29b39d442b8af5534e7ccc205c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00c5634db1fb409ea3f1f5985f133692",
              "IPY_MODEL_aa9f99f095b44ce6bdff520e250910e1",
              "IPY_MODEL_cca7a12ff04e4157aadc162a5877c7d9"
            ],
            "layout": "IPY_MODEL_379fee9b3fa442a8b4a3d3df72cd6ceb"
          }
        },
        "89b451f0350243ad97447f0ba13c540b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91f8dcdef0ad4d71a9bf89e46a10e26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c53cc5d1bb1433a80cc0e4e4ba7adb3",
              "IPY_MODEL_f47a01cd572d4342a0e359f74542a7fb",
              "IPY_MODEL_98d0da70fa7f46e2a6e8a366d399a74a"
            ],
            "layout": "IPY_MODEL_31cfaf4abd9c4bd78bceadcbdf03ce52"
          }
        },
        "935c670faf4945d892f0ae2df8fd4504": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5f972819a7847c29ecc5fa329636cf0",
              "IPY_MODEL_7ca9aefd92c944b9a120f06ea334b675",
              "IPY_MODEL_38167e3d416e4863aaa69fb0936c17d5"
            ],
            "layout": "IPY_MODEL_fa30b0d2a09c4a62a54a629ec46aa660"
          }
        },
        "9426cf71fdbc464798aabb7bff58f7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab5f9cd5dde4b228158589c0964c537",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_471a965f07ce4c108fe86d40141a7a30",
            "value": 466247
          }
        },
        "9447408cf5ae4e93ab4499284e769bae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d0da70fa7f46e2a6e8a366d399a74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51afd5a3515147109548b5363af07048",
            "placeholder": "​",
            "style": "IPY_MODEL_ee31ae0cf45542b38eec4ee06b23f4ca",
            "value": " 190/190 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "9ac9735d6d16401e9e58042cf415186a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c53cc5d1bb1433a80cc0e4e4ba7adb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24979ac4ecc4e32b6bc68f3b0a86285",
            "placeholder": "​",
            "style": "IPY_MODEL_a3ff45ea9d7942abb6baa50ddd7ff3f4",
            "value": "config.json: 100%"
          }
        },
        "9e24a94978f5499ca4630ce752ee4e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f84cc60330449e7a0941ba2f2d93649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fdb6e25c778426c8f65754c79f2835a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24979ac4ecc4e32b6bc68f3b0a86285": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d39e6b3b764f79869ccb4ecfc717a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ff45ea9d7942abb6baa50ddd7ff3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a45f74baff5e4266b76466b04085e6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a47848ac8ee343e58d65552503a6121a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a6fd1e42dfd4a988191b1aa17f39481",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e24a94978f5499ca4630ce752ee4e02",
            "value": 116
          }
        },
        "a5b79e22a66641efbbfe799f22d0431c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5fd1774e77e4e5f8142932d846d1bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a678825c0cf04510b6386f014fbb8435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60eeee1a20ed478d91b1f5a9e419a4dc",
            "placeholder": "​",
            "style": "IPY_MODEL_d4b3f58c881c4126b365affe895cc09a",
            "value": "tokenizer.json: 100%"
          }
        },
        "a6b6e461732e4e3ea91b7c7988c12cad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fc79ab819d444984b2e59a3d261eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a887214562ad4362b0bebd02f9ff70e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e063ddd8a4d74c38a98b347cc600c5c6",
            "placeholder": "​",
            "style": "IPY_MODEL_bb877bc15b4f4f5fb81fb4af34eecf69",
            "value": "modules.json: 100%"
          }
        },
        "aa651f5104cf48c08be78bdfb7ea62b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31c342be09540efb1056ad836797d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_fe19ccb814c64923852d1a38bc463a36",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "aa9f99f095b44ce6bdff520e250910e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6a0138c9e634b759ad8867da4af5fc5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c426dfbe964241a78dcf40f696ad5a",
            "value": 231508
          }
        },
        "ac02ab11bc8e45c7939d461ba997459d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac877fd801cf497796161ea7446dd24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7df6d4e33442f7b406cead0f3e1d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2e50532e39a4aba80e2c0d24377d395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ef744095724f2787f080f99fe7c137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b52bef3b092d4d328ed17b7fd98c947e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88cf91f9224425e88110e6e2dc011f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9817529ffc74e74a0a1e553bdb02f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6833a96856cb41e1bd2d2852a63914b4",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a45f74baff5e4266b76466b04085e6d3",
            "value": 10454
          }
        },
        "bb877bc15b4f4f5fb81fb4af34eecf69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbcba15fc61248f2addb124fc25b454f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be38bf25724349a28f0754f3da59dfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70689a912f7c4359b9c245dc3d868d7e",
            "placeholder": "​",
            "style": "IPY_MODEL_5345d5224df44d3c891dedef1a8a2db4",
            "value": " 349/349 [00:00&lt;00:00, 32.8kB/s]"
          }
        },
        "bfbc80a22b804c5f8b500291651c13e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80cbf90171e0462ba2b35907b4e2c955",
            "placeholder": "​",
            "style": "IPY_MODEL_a5fd1774e77e4e5f8142932d846d1bc2",
            "value": " 53.0/53.0 [00:00&lt;00:00, 6.01kB/s]"
          }
        },
        "c04c70b97fd14050a6931f4582a5dab0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c184fdae342444f3a42859c74194e07d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31c342be09540efb1056ad836797d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43d7eb9fba746ac85ea3c8f60e48849": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a887214562ad4362b0bebd02f9ff70e5",
              "IPY_MODEL_2eae978a37d5456fba401c3ac2cfd281",
              "IPY_MODEL_be38bf25724349a28f0754f3da59dfbb"
            ],
            "layout": "IPY_MODEL_bbcba15fc61248f2addb124fc25b454f"
          }
        },
        "c6a0138c9e634b759ad8867da4af5fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c61542435a4c08b2fcd11b0842adae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc71300d8e4940f581c2f1d8b05f5fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ba4a2aa8d645f99ee0443b46961e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_325261339dbb4c3baae75c0243b97894",
            "value": "model.safetensors: 100%"
          }
        },
        "cca7a12ff04e4157aadc162a5877c7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b6e461732e4e3ea91b7c7988c12cad",
            "placeholder": "​",
            "style": "IPY_MODEL_c9c61542435a4c08b2fcd11b0842adae",
            "value": " 232k/232k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "d30c30d75c2f44488b8db9d1afa55138": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b3f58c881c4126b365affe895cc09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f972819a7847c29ecc5fa329636cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80642c18a20f400f82977005f4718a4b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f84cc60330449e7a0941ba2f2d93649",
            "value": "config.json: 100%"
          }
        },
        "dd773cdea9ac4927975f0b9279a08878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e4166108d9463691f64b19d0958f6d",
            "placeholder": "​",
            "style": "IPY_MODEL_f454be89fe3c49fc86c4f4e5388d3c99",
            "value": " 350/350 [00:00&lt;00:00, 26.2kB/s]"
          }
        },
        "e063ddd8a4d74c38a98b347cc600c5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42f2b3e012f402aae40ffc63aaa94db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc71300d8e4940f581c2f1d8b05f5fd7",
              "IPY_MODEL_680378ca40984e879894417bf11a5ace",
              "IPY_MODEL_e486aa88820b4ae99ee2e853e0054116"
            ],
            "layout": "IPY_MODEL_34ed50d452de4c33bb5621930e2932c2"
          }
        },
        "e486aa88820b4ae99ee2e853e0054116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9447408cf5ae4e93ab4499284e769bae",
            "placeholder": "​",
            "style": "IPY_MODEL_16fbf1be801b4e7cb566cc9058ca2cbd",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 402MB/s]"
          }
        },
        "e4b4c421f0874d4b85b9d6cb9290230d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea543f542f224aeab710cf938d019879": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee31ae0cf45542b38eec4ee06b23f4ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0fd25ed81cd43989b46b29e33aac2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ec1099ec064a9391b2c1dfe16ae517": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a678825c0cf04510b6386f014fbb8435",
              "IPY_MODEL_9426cf71fdbc464798aabb7bff58f7f9",
              "IPY_MODEL_4e9d93e62e8245c3989abef76ae7016b"
            ],
            "layout": "IPY_MODEL_d30c30d75c2f44488b8db9d1afa55138"
          }
        },
        "f454be89fe3c49fc86c4f4e5388d3c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47a01cd572d4342a0e359f74542a7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4098339497fe411d9465c174831c308d",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89b451f0350243ad97447f0ba13c540b",
            "value": 190
          }
        },
        "f58584d6c720411882e46f327f7c7f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde2ca94fd4c4ee3aa97ef716c3d24f2",
            "placeholder": "​",
            "style": "IPY_MODEL_ac877fd801cf497796161ea7446dd24b",
            "value": "README.md: 100%"
          }
        },
        "f694a0297f3b49688d8c498632f26ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e50532e39a4aba80e2c0d24377d395",
            "placeholder": "​",
            "style": "IPY_MODEL_00140994568049dd801a8dfb4333bebf",
            "value": " 112/112 [00:00&lt;00:00, 7.60kB/s]"
          }
        },
        "fa30b0d2a09c4a62a54a629ec46aa660": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3e622aae52401d8b00174e682fcd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fde2ca94fd4c4ee3aa97ef716c3d24f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe19ccb814c64923852d1a38bc463a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
